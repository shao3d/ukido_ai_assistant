# llamaindex_ingest.py (–§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π + –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥)
"""
–§–∏–Ω–∞–ª—å–Ω–∞—è, –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –≤ Pinecone.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (Markdown -> Semantic) –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
–≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ RAG.

–î–ª—è –∑–∞–ø—É—Å–∫–∞:
1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ requirements.txt.
2. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª 'questions.txt' —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏-–ø—Ä–∏–º–µ—Ä–∞–º–∏.
3. –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É 'data_facts' —Å –≤–∞—à–∏–º–∏ .md —Ñ–∞–π–ª–∞–º–∏.
4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç: python llamaindex_ingest.py
"""
import logging
import os
import pinecone
from llama_index.core import (
    SimpleDirectoryReader,
    StorageContext,
    Settings,
    PromptTemplate,
)
from llama_index.core.node_parser import (
    MarkdownNodeParser,
    SemanticSplitterNodeParser,
)
from llama_index.core.ingestion import IngestionPipeline
from llama_index.core.extractors import QuestionsAnsweredExtractor
from llama_index.vector_stores.pinecone import PineconeVectorStore
from llama_index.embeddings.gemini import GeminiEmbedding
from llama_index.llms.openrouter import OpenRouter

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å 'config' –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∏–∑ –ø–æ–¥–ø–∞–ø–∫–∏.
# –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ config.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
try:
    from config import config
except ImportError:
    import sys
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from config import config


# --- –ù–ê–°–¢–†–û–ô–ö–ê ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
PINECONE_INDEX_NAME = "ukido"
DATA_DIRECTORY = "data_facts"
QUESTIONS_FILE = "questions.txt"

def load_questions(filepath: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –∏–∑ —Ñ–∞–π–ª–∞."""
    logger = logging.getLogger(__name__)
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            questions = [line.strip() for line in f if line.strip()]
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤-–ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ '{filepath}'.")
        return "\n".join(f"{i+1}. {q}" for i, q in enumerate(questions))
    except FileNotFoundError:
        logger.error(f"‚ùå –§–∞–π–ª —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ '{filepath}' –Ω–µ –Ω–∞–π–¥–µ–Ω! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –ª–µ–∂–∏—Ç —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")
        raise

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""
    logger = logging.getLogger(__name__)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –§–ò–ù–ê–õ–¨–ù–û–ô –≤–µ—Ä—Å–∏–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–°—Ç—Ä—É–∫—Ç—É—Ä–∞ -> –°–µ–º–∞–Ω—Ç–∏–∫–∞)...")

    # --- 1. –ó–ê–ì–†–£–ó–ö–ê –í–û–ü–†–û–°–û–í-–ü–†–ò–ú–ï–†–û–í ---
    example_questions = load_questions(QUESTIONS_FILE)

    # --- 2. –ù–ê–°–¢–†–û–ô–ö–ê –ú–û–î–ï–õ–ï–ô ---
    logger.info("‚öôÔ∏è  –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    # LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–µ—Ç–∞-–≤–æ–ø—Ä–æ—Å–æ–≤ (–±—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è)
    llm = OpenRouter(api_key=config.OPENROUTER_API_KEY, model="mistralai/mistral-7b-instruct-v0.2")
    # –ú–æ–¥–µ–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
    embed_model = GeminiEmbedding(model_name=config.EMBEDDING_MODEL, api_key=config.GEMINI_API_KEY)
    Settings.llm = llm
    Settings.embed_model = embed_model
    
    # --- 3. –ù–ê–°–¢–†–û–ô–ö–ê –ü–†–û–ú–ü–¢–ê –î–õ–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –í–û–ü–†–û–°–û–í ---
    qa_generate_prompt_tmpl = PromptTemplate(
        "–ù–∏–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n"
        "---------------------\n"
        "{context_str}\n"
        "---------------------\n"
        "–ò—Å–ø–æ–ª—å–∑—É—è —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è, "
        "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π {num_questions} –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n"
        "–í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Å—Ç–∏–ª–µ –∏ –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ, –∫–∞–∫ –≤ —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö:\n"
        "--- –ü–†–ò–ú–ï–†–´ –í–û–ü–†–û–°–û–í ---\n"
        "{example_questions}\n"
        "------------------------\n"
        "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã:\n"
    )
    qa_generate_prompt = qa_generate_prompt_tmpl.partial_format(example_questions=example_questions)

    # --- 4. –ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í ---
    logger.info(f"üìÇ –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ '{DATA_DIRECTORY}'...")
    documents = SimpleDirectoryReader(DATA_DIRECTORY, required_exts=[".md"]).load_data()

    # --- 5. –ù–ê–°–¢–†–û–ô–ö–ê –î–í–£–•–°–¢–£–ü–ï–ù–ß–ê–¢–û–ì–û –ö–û–ù–í–ï–ô–ï–†–ê –û–ë–†–ê–ë–û–¢–ö–ò ---
    logger.info("üî™ –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –î–í–£–•–°–¢–£–ü–ï–ù–ß–ê–¢–û–ì–û –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
    
    question_extractor = QuestionsAnsweredExtractor(
        questions=5,
        prompt_template=qa_generate_prompt,
        llm=llm,
    )

    pipeline = IngestionPipeline(
        transformations=[
            # –≠–¢–ê–ü 1: –ì—Ä—É–±–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º Markdown
            MarkdownNodeParser(include_metadata=True),
            
            # –≠–¢–ê–ü 2: –¢–æ–Ω–∫–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Ä–µ–∑–∫–∞ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –±–ª–æ–∫–∞
            SemanticSplitterNodeParser(
                buffer_size=1,
                breakpoint_percentile_threshold=95,
                embed_model=embed_model
            ),
            
            # –≠–¢–ê–ü 3: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –º–µ—Ç–∞-–≤–æ–ø—Ä–æ—Å–∞–º–∏
            question_extractor,
            
            # –≠–¢–ê–ü 4: –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
            embed_model,
        ],
    )
    
    logger.info("üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
    nodes = pipeline.run(documents=documents, show_progress=True)
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(nodes)} —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö, —É–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.")

    # --- 6. –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï –ö PINECONE –ò –ó–ê–ì–†–£–ó–ö–ê ---
    logger.info(f"üå≤ –®–∞–≥ 4: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Pinecone –∏ –æ—á–∏—Å—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ '{PINECONE_INDEX_NAME}'...")
    pc = pinecone.Pinecone(api_key=config.PINECONE_API_KEY)
    pinecone_index = pc.Index(PINECONE_INDEX_NAME)
    pinecone_index.delete(delete_all=True)
    logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å –æ—á–∏—â–µ–Ω.")

    logger.info("üì§ –®–∞–≥ 5: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≤ Pinecone...")
    vector_store = PineconeVectorStore(pinecone_index=pinecone_index)
    vector_store.add(nodes)
    
    stats = pinecone_index.describe_index_stats()
    logger.info(f"üéâüéâüéâ –£–°–ü–ï–•! –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í –±–∞–∑–µ {stats.get('total_vector_count', 'N/A')} –≤–µ–∫—Ç–æ—Ä–æ–≤. üéâüéâüéâ")

if __name__ == "__main__":
    if not os.path.isdir(DATA_DIRECTORY):
        print(f"‚ùå –ü–∞–ø–∫–∞ '{DATA_DIRECTORY}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ –µ–µ –∏ –ø–æ–ª–æ–∂–∏—Ç–µ —Ç—É–¥–∞ –≤–∞—à–∏ .md —Ñ–∞–π–ª—ã.")
    elif not os.path.exists(QUESTIONS_FILE):
        print(f"‚ùå –§–∞–π–ª '{QUESTIONS_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ –∏ –Ω–∞–ø–æ–ª–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å–∞–º–∏.")
    else:
        main()