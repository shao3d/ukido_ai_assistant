import os
import time
import google.generativeai as genai
from pinecone import Pinecone
from dotenv import load_dotenv
import re
import numpy as np
from typing import List, Tuple
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
try:
    from sentence_transformers import SentenceTransformer
    import torch
    from sklearn.metrics.pairwise import cosine_similarity
    LOCAL_MODELS_AVAILABLE = True
    print("‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã")
except ImportError:
    LOCAL_MODELS_AVAILABLE = False
    print("‚ö†Ô∏è –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Gemini API.")

# --- –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø i7-6700HQ ---
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_HOST_FACTS = os.getenv("PINECONE_HOST_FACTS")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è —Ç–≤–æ–µ–≥–æ –∂–µ–ª–µ–∑–∞
CONFIG = {
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á–∞–Ω–∫–∏–Ω–≥–∞
    "min_chunk_size": 800,
    "max_chunk_size": 2200,          # –ù–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    "target_chunk_size": 1400,       # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Ç–≤–æ–∏—Ö –∑–∞–¥–∞—á
    "similarity_threshold": 0.72,    # –ß—É—Ç—å –≤—ã—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    "sentence_window": 3,
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    "model_name": "paraphrase-multilingual-MiniLM-L12-v2",  # –ö–æ–º–ø—Ä–æ–º–∏—Å—Å: –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è + –±—ã—Å—Ç—Ä–∞—è
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è i7-6700HQ
    "max_threads": 6,                # –û—Å—Ç–∞–≤–ª—è–µ–º 2 –ø–æ—Ç–æ–∫–∞ —Å–∏—Å—Ç–µ–º–µ
    "batch_size": 4,                 # –ù–µ–±–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    "api_delay": 0.4,                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É API –∑–∞–ø—Ä–æ—Å–∞–º–∏
    "processing_delay": 0.2,         # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    "memory_limit_gb": 8,            # –õ–∏–º–∏—Ç –¥–ª—è AI –æ–ø–µ—Ä–∞—Ü–∏–π (–ø–æ–ª–æ–≤–∏–Ω–∞ –æ—Ç –æ–±—â–µ–π)
    "cpu_threshold": 75,             # –ü–æ—Ä–æ–≥ –∑–∞–≥—Ä—É–∑–∫–∏ CPU
    "temp_check_interval": 10,       # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 10 –æ–ø–µ—Ä–∞—Ü–∏–π
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
genai.configure(api_key=GEMINI_API_KEY)
embedding_model = 'models/text-embedding-004'
pc = Pinecone(api_key=PINECONE_API_KEY)

class SystemMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ i7-6700HQ"""
    
    @staticmethod
    def get_system_status():
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        
        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory_percent,
            "memory_available_gb": memory.available / (1024**3)
        }
    
    @staticmethod
    def should_take_break():
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–∞ –ª–∏ –ø–∞—É–∑–∞ —Å–∏—Å—Ç–µ–º–µ"""
        status = SystemMonitor.get_system_status()
        
        if status["cpu_percent"] > CONFIG["cpu_threshold"]:
            return True, f"–í—ã—Å–æ–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CPU: {status['cpu_percent']:.1f}%"
        
        if status["memory_percent"] > 85:
            return True, f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {status['memory_percent']:.1f}%"
        
        return False, "–°–∏—Å—Ç–µ–º–∞ –≤ –Ω–æ—Ä–º–µ"
    
    @staticmethod
    def wait_for_system_cooldown():
        """–ñ–¥–µ—Ç —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ —Å–∏—Å—Ç–µ–º—É"""
        print("      üå°Ô∏è –î–∞—é —Å–∏—Å—Ç–µ–º–µ –æ—Å—Ç—ã—Ç—å...")
        
        while True:
            time.sleep(3)  # –ü–∞—É–∑–∞ –¥–ª—è –æ—Å—Ç—ã–≤–∞–Ω–∏—è
            needs_break, reason = SystemMonitor.should_take_break()
            
            if not needs_break:
                print("      ‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—é —Ä–∞–±–æ—Ç—ã")
                break
            else:
                print(f"      ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ: {reason}")

class OptimizedSemanticChunker:
    """
    –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–µ—Ä, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è i7-6700HQ
    –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º —Ä–∞–±–æ—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
    """
    
    def __init__(self):
        self.local_model = None
        self.operation_count = 0
        self._init_local_model()
        self._display_system_info()
    
    def _display_system_info(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"""
        status = SystemMonitor.get_system_status()
        
        print("üñ•Ô∏è –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –°–ò–°–¢–ï–ú–ï:")
        print(f"   üíª CPU: Intel i7-6700HQ (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {status['cpu_percent']:.1f}%)")
        print(f"   üß† –û–ó–£: {status['memory_available_gb']:.1f} –ì–ë –¥–æ—Å—Ç—É–ø–Ω–æ –∏–∑ 16 –ì–ë")
        print(f"   ‚öôÔ∏è –ü–æ—Ç–æ–∫–æ–≤ –¥–ª—è AI: {CONFIG['max_threads']} –∏–∑ 8")
        print(f"   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {CONFIG['batch_size']}")
        print(f"   üéØ –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {CONFIG['target_chunk_size']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   üß† –ú–æ–¥–µ–ª—å: {CONFIG['model_name']}")
    
    def _init_local_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è —Ç–≤–æ–µ–≥–æ –∂–µ–ª–µ–∑–∞"""
        if not LOCAL_MODELS_AVAILABLE:
            print("üåê –†–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å Gemini API (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º)")
            return
        
        try:
            print(f"üöÄ –ó–∞–≥—Ä—É–∂–∞—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.local_model = SentenceTransformer(CONFIG['model_name'])
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –¥–ª—è CPU
            self.local_model = self.local_model.cpu()
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ PyTorch
            torch.set_num_threads(CONFIG['max_threads'])
            torch.set_num_interop_threads(2)  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            print("   ‚ö° –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ç–≤–æ–µ–º –∂–µ–ª–µ–∑–µ...")
            start_time = time.time()
            
            test_embeddings = self.local_model.encode(
                ["–¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏"],
                batch_size=1,
                show_progress_bar=False
            )
            
            test_time = time.time() - start_time
            print(f"   ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {test_time:.3f}—Å")
            
            if test_time > 2.0:
                print("   ‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞. –†–µ–∫–æ–º–µ–Ω–¥—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ API —Ä–µ–∂–∏–º.")
                self.local_model = None
            else:
                print("   ‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            print("   üåê –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ API-only —Ä–µ–∂–∏–º")
            self.local_model = None
    
    def _check_system_periodically(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        self.operation_count += 1
        
        if self.operation_count % CONFIG["temp_check_interval"] == 0:
            needs_break, reason = SystemMonitor.should_take_break()
            
            if needs_break:
                print(f"      ‚è∏Ô∏è {reason}")
                SystemMonitor.wait_for_system_cooldown()
    
    def split_into_sentences(self, text: str) -> List[str]:
        """–£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
        # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä—É—Å—Å–∫–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        sentences = re.split(r'[.!?]+(?:\s|$)', text)
        
        clean_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
            if len(sentence) > 25 and not sentence.isdigit():
                clean_sentences.append(sentence)
        
        return clean_sentences
    
    def calculate_semantic_breaks(self, sentences: List[str]) -> List[float]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑—Ä—ã–≤—ã —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        if not self.local_model or len(sentences) < 2:
            # API fallback - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            return [0.6 + (i % 3) * 0.1 for i in range(len(sentences) - 1)]
        
        try:
            print(f"      üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º—É –ø–µ—Ä–µ–¥ —Ç—è–∂–µ–ª–æ–π –æ–ø–µ—Ä–∞—Ü–∏–µ–π
            self._check_system_periodically()
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            max_sentences = 20  # –†–∞–∑—É–º–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —Ç–≤–æ–µ–≥–æ –∂–µ–ª–µ–∑–∞
            if len(sentences) > max_sentences:
                print(f"      üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–µ—Ä–≤—ã–µ {max_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
                sentences = sentences[:max_sentences]
            
            # –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
            windows = []
            for i in range(len(sentences)):
                start = max(0, i - CONFIG['sentence_window'] // 2)
                end = min(len(sentences), i + CONFIG['sentence_window'] // 2 + 1)
                window = " ".join(sentences[start:end])
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ–∫–Ω–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                if len(window) > 500:
                    window = window[:500] + "..."
                windows.append(window)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –±–∞—Ç—á–∞–º–∏
            embeddings = self.local_model.encode(
                windows,
                batch_size=CONFIG['batch_size'],
                show_progress_bar=False,
                normalize_embeddings=True  # –£—Å–∫–æ—Ä—è–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
            )
            
            # –ü–∞—É–∑–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
            time.sleep(CONFIG["processing_delay"])
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
            similarities = []
            for i in range(len(embeddings) - 1):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º dot product –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ)
                similarity = np.dot(embeddings[i], embeddings[i + 1])
                similarities.append(float(similarity))
            
            avg_similarity = np.mean(similarities)
            print(f"      üìä –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–≤—è–∑–Ω–æ—Å—Ç—å: {avg_similarity:.3f}")
            
            return similarities
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            print(f"      üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–µ fallback –∑–Ω–∞—á–µ–Ω–∏—è
            return [0.6] * (len(sentences) - 1)
    
    def create_semantic_chunks(self, text: str, source_filename: str) -> List[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–µ —á–∞–Ω–∫–∏ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
        """
        print(f"   ‚úÇÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {source_filename}")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = self.split_into_sentences(text)
        if len(sentences) < 2:
            return [text] if len(text) > CONFIG['min_chunk_size'] else []
        
        print(f"      üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(sentences)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑—Ä—ã–≤—ã (—Å —É—á–µ—Ç–æ–º –Ω–∞–≥—Ä—É–∑–∫–∏)
        similarities = self.calculate_semantic_breaks(sentences)
        
        # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
        chunks = []
        current_chunk = []
        current_size = 0
        
        for i, sentence in enumerate(sentences):
            current_chunk.append(sentence)
            current_size += len(sentence)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ—á–∫–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            should_split = False
            
            # –î–æ—Å—Ç–∏–≥–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            if current_size >= CONFIG['max_chunk_size']:
                should_split = True
                reason = "–º–∞–∫—Å. —Ä–∞–∑–º–µ—Ä"
            
            # –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä + —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑—Ä—ã–≤
            elif (current_size >= CONFIG['target_chunk_size'] and 
                  i < len(similarities) and 
                  similarities[i] < CONFIG['similarity_threshold']):
                should_split = True
                reason = "—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑—Ä—ã–≤"
            
            # –°–∏–ª—å–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑—Ä—ã–≤ (–Ω–æ–≤–∞—è —Ç–µ–º–∞)
            elif (i < len(similarities) and 
                  similarities[i] < 0.45 and 
                  current_size >= CONFIG['min_chunk_size']):
                should_split = True
                reason = "—Å–º–µ–Ω–∞ —Ç–µ–º—ã"
            
            if should_split:
                chunk_text = ". ".join(current_chunk).strip()
                if len(chunk_text) >= CONFIG['min_chunk_size']:
                    chunks.append(chunk_text)
                    print(f"      ‚úÖ –ß–∞–Ω–∫ {len(chunks)}: {len(chunk_text)} —Å–∏–º–≤–æ–ª–æ–≤ ({reason})")
                
                current_chunk = []
                current_size = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫
        if current_chunk:
            chunk_text = ". ".join(current_chunk).strip()
            if len(chunk_text) >= CONFIG['min_chunk_size']:
                chunks.append(chunk_text)
                print(f"      ‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫: {len(chunk_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        print(f"   üéØ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
        return chunks
    
    def process_and_upload(self, directory_path: str, index_name: str):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        start_time = time.time()
        
        print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –ß–ê–ù–ö–ï–† –î–õ–Ø i7-6700HQ")
        print("=" * 65)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Pinecone
        try:
            index = pc.Index(host=PINECONE_HOST_FACTS)
            print("üîå –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ Pinecone")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Pinecone: {e}")
            return
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å
        print("üóëÔ∏è –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å...")
        index.delete(delete_all=True)
        time.sleep(3)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        txt_files = [f for f in os.listdir(directory_path) if f.endswith(".txt")]
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(txt_files)}")
        
        vector_count = 0
        total_chunks = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
        for file_idx, filename in enumerate(txt_files):
            print(f"\nüìñ –§–∞–π–ª {file_idx + 1}/{len(txt_files)}: {filename}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º—É –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ñ–∞–π–ª–∞
            needs_break, reason = SystemMonitor.should_take_break()
            if needs_break:
                print(f"   ‚è∏Ô∏è {reason}")
                SystemMonitor.wait_for_system_cooldown()
            
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            try:
                with open(os.path.join(directory_path, filename), 'r', encoding='utf-8') as f:
                    content = f.read().strip()
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
                continue
            
            if len(content) < 200:
                print("   ‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏
            chunks = self.create_semantic_chunks(content, filename)
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä—É–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º —á–∞–Ω–∫–∏
            print(f"   üîÑ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è {len(chunks)} —á–∞–Ω–∫–æ–≤...")
            
            for chunk_idx, chunk in enumerate(chunks):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º—É –∫–∞–∂–¥—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–π
                    if chunk_idx % 3 == 0:
                        self._check_system_periodically()
                    
                    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ Gemini API
                    embedding = genai.embed_content(
                        model=embedding_model,
                        content=chunk,
                        task_type="RETRIEVAL_DOCUMENT"
                    )
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Pinecone
                    vector_data = {
                        "id": f"{index_name}-optimized-{vector_count}",
                        "values": embedding['embedding'],
                        "metadata": {
                            "text": chunk,
                            "source": filename,
                            "chunk_index": chunk_idx,
                            "chunk_size": len(chunk),
                            "method": "semantic_i7_optimized",
                            "model": CONFIG['model_name']
                        }
                    }
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Pinecone
                    index.upsert(vectors=[vector_data])
                    vector_count += 1
                    total_chunks += 1
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É API –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    time.sleep(CONFIG["api_delay"])
                    
                except Exception as e:
                    print(f"      ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞ {chunk_idx}: {e}")
                    time.sleep(1)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                    continue
            
            print(f"   ‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(chunks)} —á–∞–Ω–∫–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –¥–ª—è –æ—Å—Ç—ã–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
            time.sleep(2)
        
        total_time = time.time() - start_time
        
        print(f"\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("=" * 50)
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   üìÅ –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(txt_files)}")
        print(f"   üìù –ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {total_chunks}")
        print(f"   üíæ –í–µ–∫—Ç–æ—Ä–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {vector_count}")
        print(f"   ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
        print(f"   üéØ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —á–∞–Ω–∫: {total_time/max(total_chunks,1):.2f}—Å")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        time.sleep(3)
        stats = index.describe_index_stats()
        print(f"‚úÖ –í –∏–Ω–¥–µ–∫—Å–µ Pinecone: {stats.total_vector_count} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø–æ—Å–ª–µ —Ä–∞–±–æ—Ç—ã
        final_status = SystemMonitor.get_system_status()
        print(f"üñ•Ô∏è –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã:")
        print(f"   CPU: {final_status['cpu_percent']:.1f}%")
        print(f"   –û–ó–£: {final_status['memory_percent']:.1f}%")

def main():
    """–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —á–∞–Ω–∫–µ—Ä–∞"""
    print("–ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–µ—Ä –¥–ª—è i7-6700HQ...")
    
    chunker = OptimizedSemanticChunker()
    chunker.process_and_upload("data_facts", "ukido")
    
    print("\nüèÅ –í—Å–µ –≥–æ—Ç–æ–≤–æ! –¢–≤–æ–π –Ω–æ—É—Ç–±—É–∫ –º–æ–∂–µ—Ç –æ—Ç–¥–æ—Ö–Ω—É—Ç—å üòä")

if __name__ == "__main__":
    main()
