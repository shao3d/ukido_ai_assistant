import os
import time
import google.generativeai as genai
from pinecone import Pinecone
from dotenv import load_dotenv
import re

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ò –ó–ê–ì–†–£–ó–ö–ê –ö–õ–Æ–ß–ï–ô ---
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_HOST_FACTS = os.getenv("PINECONE_HOST_FACTS")

if not all([GEMINI_API_KEY, PINECONE_API_KEY, PINECONE_HOST_FACTS]):
    raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å –≤—Å–µ –∫–ª—é—á–∏ –≤ —Ñ–∞–π–ª–µ .env")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í ---
genai.configure(api_key=GEMINI_API_KEY)
embedding_model = 'models/text-embedding-004'
pc = Pinecone(api_key=PINECONE_API_KEY)

def clear_pinecone_index(index):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å Pinecone –æ—Ç –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
    –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–º–µ–Ω—ã –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤—ã–º–∏.
    """
    print("üóëÔ∏è –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å –æ—Ç —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞
        stats = index.describe_index_stats()
        total_vectors = stats.total_vector_count
        
        if total_vectors == 0:
            print("   ‚úÖ –ò–Ω–¥–µ–∫—Å —É–∂–µ –ø—É—Å—Ç")
            return
        
        print(f"   üìä –ù–∞–π–¥–µ–Ω–æ {total_vectors} –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≤–µ–∫—Ç–æ—Ä—ã (delete_all - —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ Pinecone)
        index.delete(delete_all=True)
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏ —É–¥–∞–ª–µ–Ω–∏—è
        print("   ‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è...")
        time.sleep(5)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        stats = index.describe_index_stats()
        print(f"   ‚úÖ –ò–Ω–¥–µ–∫—Å –æ—á–∏—â–µ–Ω. –û—Å—Ç–∞–ª–æ—Å—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {stats.total_vector_count}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        raise e

def analyze_chunk_completeness(chunk_text, context_info=""):
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —á–∞–Ω–∫–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –≥—Ä–∞–Ω–∏—Ü —á–∞–Ω–∫–∞.
    """
    analysis_prompt = f"""
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–∫—Å—Ç–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –µ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏.

–ö–û–ù–¢–ï–ö–°–¢: –≠—Ç–æ —á–∞—Å—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–µ—Ç—Å–∫–æ–π —à–∫–æ–ª–µ —Ä–∞–∑–≤–∏—Ç–∏—è soft-skills "Ukido". 
{context_info}

–ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú–´–ô –§–†–ê–ì–ú–ï–ù–¢:
"{chunk_text}"

–ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º –∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–º –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–µ –ø–æ–∏—Å–∫–∞.

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:
–°–¢–ê–¢–£–°: [–ó–ê–í–ï–†–®–ï–ù/–ù–ï–ó–ê–í–ï–†–®–ï–ù/–ß–ê–°–¢–ò–ß–ù–û_–ó–ê–í–ï–†–®–ï–ù]
–ü–†–ò–ß–ò–ù–ê: [–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ]
–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: [—á—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∏–ª–∏ –∫–∞–∫ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã]
–ö–õ–Æ–ß–ï–í–´–ï_–¢–ï–ú–´: [2-3 –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞]
"""
    
    try:
        response = genai.GenerativeModel('gemini-1.5-flash').generate_content(analysis_prompt)
        return response.text.strip()
    except Exception as e:
        print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–∞–Ω–∫–∞: {e}")
        return "–°–¢–ê–¢–£–°: –ß–ê–°–¢–ò–ß–ù–û_–ó–ê–í–ï–†–®–ï–ù\n–ü–†–ò–ß–ò–ù–ê: –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å"

def create_intelligent_chunks(content, filename):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é AI-–∞–Ω–∞–ª–∏–∑–∞.
    –≠—Ç–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–µ—Ä—Å–∏—è —á–∞–Ω–∫–∏–Ω–≥–∞, –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–º—ã—Å–ª–æ–≤—É—é —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å.
    """
    print(f"   üß† –ù–∞—á–∏–Ω–∞—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ {filename}")
    
    # –≠—Ç–∞–ø 1: –ü–µ—Ä–≤–∏—á–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
    # –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ —è–≤–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ—Ä—ã –ø–æ—Å—Ç–∞–≤–∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ
    primary_sections = re.split(r'\n---\n', content)
    print(f"   üìã –ù–∞–π–¥–µ–Ω–æ {len(primary_sections)} –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤")
    
    intelligent_chunks = []
    
    for section_idx, section in enumerate(primary_sections):
        section = section.strip()
        if not section or len(section) < 100:
            continue
            
        print(f"   üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–∞–∑–¥–µ–ª {section_idx + 1} (–¥–ª–∏–Ω–∞: {len(section)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –≠—Ç–∞–ø 2: –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–≥–æ —Ü–µ–ª–∏–∫–æ–º
        if len(section) <= 1200:
            analysis = analyze_chunk_completeness(
                section, 
                f"–†–∞–∑–¥–µ–ª {section_idx + 1} –∏–∑ —Ñ–∞–π–ª–∞ {filename}"
            )
            print(f"      ü§ñ AI –∞–Ω–∞–ª–∏–∑: {analysis.split('–°–¢–ê–¢–£–°:')[1].split('–ü–†–ò–ß–ò–ù–ê:')[0].strip()}")
            intelligent_chunks.append(section)
            
        # –≠—Ç–∞–ø 3: –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º —É–º–Ω–æ
        else:
            print(f"      ‚úÇÔ∏è –†–∞–∑–¥–µ–ª –±–æ–ª—å—à–æ–π, –≤—ã–ø–æ–ª–Ω—è—é –ø–æ–¥—Ä–∞–∑–±–∏–µ–Ω–∏–µ")
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º (–¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏)
            paragraphs = re.split(r'\n\n', section)
            
            current_chunk = ""
            for para_idx, paragraph in enumerate(paragraphs):
                paragraph = paragraph.strip()
                if not paragraph:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—Ç–∞–Ω–µ—Ç –ª–∏ —á–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º
                potential_chunk = current_chunk + "\n\n" + paragraph if current_chunk else paragraph
                
                if len(potential_chunk) > 1000 and current_chunk:
                    # –¢–µ–∫—É—â–∏–π —á–∞–Ω–∫ –≥–æ—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–≥–æ
                    analysis = analyze_chunk_completeness(
                        current_chunk,
                        f"–ß–∞—Å—Ç—å —Ä–∞–∑–¥–µ–ª–∞ {section_idx + 1}, –∞–±–∑–∞—Ü—ã –¥–æ {para_idx}"
                    )
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
                    status = "–ß–ê–°–¢–ò–ß–ù–û_–ó–ê–í–ï–†–®–ï–ù"  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    if "–°–¢–ê–¢–£–°:" in analysis:
                        status = analysis.split("–°–¢–ê–¢–£–°:")[1].split("–ü–†–ò–ß–ò–ù–ê:")[0].strip()
                    
                    print(f"         üéØ –ü–æ–¥—á–∞–Ω–∫ –≥–æ—Ç–æ–≤, AI —Å—Ç–∞—Ç—É—Å: {status}")
                    intelligent_chunks.append(current_chunk)
                    current_chunk = paragraph
                else:
                    current_chunk = potential_chunk
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫ —Ä–∞–∑–¥–µ–ª–∞
            if current_chunk:
                analysis = analyze_chunk_completeness(
                    current_chunk,
                    f"–ó–∞–≤–µ—Ä—à–∞—é—â–∞—è —á–∞—Å—Ç—å —Ä–∞–∑–¥–µ–ª–∞ {section_idx + 1}"
                )
                status = "–ß–ê–°–¢–ò–ß–ù–û_–ó–ê–í–ï–†–®–ï–ù"
                if "–°–¢–ê–¢–£–°:" in analysis:
                    status = analysis.split("–°–¢–ê–¢–£–°:")[1].split("–ü–†–ò–ß–ò–ù–ê:")[0].strip()
                print(f"         üéØ –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ–¥—á–∞–Ω–∫, AI —Å—Ç–∞—Ç—É—Å: {status}")
                intelligent_chunks.append(current_chunk)
    
    print(f"   ‚úÖ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(intelligent_chunks)} —á–∞–Ω–∫–æ–≤")
    return intelligent_chunks

def process_and_upload_updated_data(directory_path, pinecone_index, index_name):
    """
    –ß–∏—Ç–∞–µ—Ç –≤—Å–µ .txt —Ñ–∞–π–ª—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —Å–æ–∑–¥–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
    —Å –ø–æ–º–æ—â—å—é AI-–∞–Ω–∞–ª–∏–∑–∞, —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ Pinecone.
    
    –≠—Ç–∞ –≤–µ—Ä—Å–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥.
    """
    print(f"\nüìö –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {directory_path}")
    print("üß† –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥ —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º")
    
    vector_id_counter = 0
    total_chunks = 0
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö txt —Ñ–∞–π–ª–æ–≤
    txt_files = [f for f in os.listdir(directory_path) if f.endswith(".txt")]
    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(txt_files)}")
    
    for file_idx, filename in enumerate(txt_files):
        file_path = os.path.join(directory_path, filename)
        print(f"\nüìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª {file_idx + 1}/{len(txt_files)}: {filename}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        if not content:
            print(f"   ‚ö†Ô∏è –§–∞–π–ª {filename} –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞—é")
            continue
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥
        intelligent_chunks = create_intelligent_chunks(content, filename)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —á–∞–Ω–∫
        for chunk_idx, chunk in enumerate(intelligent_chunks):
            if not chunk or len(chunk.strip()) < 50:
                continue
                
            print(f"   üîÑ –°–æ–∑–¥–∞—é –≤–µ–∫—Ç–æ—Ä –¥–ª—è —á–∞–Ω–∫–∞ {chunk_idx + 1}/{len(intelligent_chunks)} (–¥–ª–∏–Ω–∞: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            try:
                # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                embedding = genai.embed_content(
                    model=embedding_model,
                    content=chunk,
                    task_type="RETRIEVAL_DOCUMENT",
                    title=f"Intelligent chunk from {filename}"
                )
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Pinecone
                vector_to_upsert = {
                    "id": f"{index_name}-{vector_id_counter}",
                    "values": embedding['embedding'],
                    "metadata": {
                        "text": chunk,
                        "source": filename,
                        "chunk_index": chunk_idx,
                        "chunk_length": len(chunk),
                        "chunking_method": "intelligent_semantic"
                    }
                }
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Pinecone
                pinecone_index.upsert(vectors=[vector_to_upsert])
                print(f"      ‚úÖ –í–µ–∫—Ç–æ—Ä {vector_to_upsert['id']} –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                
                vector_id_counter += 1
                total_chunks += 1
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                time.sleep(1)

            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ ‚Ññ{chunk_idx + 1}: {e}")
                print(f"      üìÑ –ü—Ä–æ–±–ª–µ–º–Ω—ã–π —Ç–µ–∫—Å—Ç: {chunk[:100]}...")
                continue

    print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(txt_files)}")
    print(f"   üìù –°–æ–∑–¥–∞–Ω–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —á–∞–Ω–∫–æ–≤: {total_chunks}")
    print(f"   üíæ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å: {vector_id_counter}")
    print("üß† –í—Å–µ —á–∞–Ω–∫–∏ –ø—Ä–æ—à–ª–∏ AI-–∞–Ω–∞–ª–∏–∑ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å")

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã —Ñ–∞–∫—Ç–æ–≤
    """
    print("üöÄ –û–ë–ù–û–í–õ–ï–ù–ò–ï –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô UKIDO")
    print("=" * 50)
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∏–Ω–¥–µ–∫—Å—É —Ñ–∞–∫—Ç–æ–≤
        print("üîå –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ Pinecone...")
        index_facts = pc.Index(host=PINECONE_HOST_FACTS)
        print("   ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = index_facts.describe_index_stats()
        print(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞: {stats.total_vector_count} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –Ω–∞ –æ—á–∏—Å—Ç–∫—É
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –°–µ–π—á–∞—Å –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã—Ö!")
        print("   –í—Å–µ —Å—Ç–∞—Ä—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏ –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–æ–≤—ã–º–∏.")
        
        # –í –ø—Ä–æ–¥–∞–∫—à–Ω —Å—Ä–µ–¥–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å input() –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        # response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (yes/no): ")
        # if response.lower() != 'yes':
        #     print("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
        #     return
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å
        clear_pinecone_index(index_facts)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        process_and_upload_updated_data("data_facts", index_facts, "ukido")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
        time.sleep(3)  # –ñ–¥–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        final_stats = index_facts.describe_index_stats()
        print(f"üìä –ù–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞: {final_stats.total_vector_count} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        
        print("\nüéä –û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("   RAG —Å–∏—Å—Ç–µ–º–∞ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
        
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("   –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É")

if __name__ == "__main__":
    main()
