# llamaindex_rag.py (–í–µ—Ä—Å–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è gpt-4o-mini)
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG —Å–∏—Å—Ç–µ–º–æ–π –Ω–∞ –±–∞–∑–µ LlamaIndex.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ (app.py) –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
–í–∫–ª—é—á–∞–µ—Ç —Ä–µ—Ä–∞–Ω–∫–µ—Ä –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤:
- –ú–æ–¥–µ–ª—å: openai/gpt-4o-mini (–¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤)
- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: Gemini
"""
import logging
import time
from typing import Tuple, Dict, Any

import pinecone
from llama_index.core import VectorStoreIndex, Settings
from llama_index.vector_stores.pinecone import PineconeVectorStore
from llama_index.llms.openrouter import OpenRouter
from llama_index.embeddings.gemini import GeminiEmbedding
from llama_index.core.postprocessor import SentenceTransformerRerank

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å 'config' –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∏–∑ –ø–æ–¥–ø–∞–ø–∫–∏.
# –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ config.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
try:
    from config import config
except ImportError:
    import os
    import sys
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from config import config


class LlamaIndexRAG:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG —Å–∏—Å—Ç–µ–º–æ–π –Ω–∞ –±–∞–∑–µ LlamaIndex —Å —Ä–µ—Ä–∞–Ω–∫–µ—Ä–æ–º.
    """
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.pinecone_index_name = "ukido"
        self.query_engine = None

        try:
            # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π
            # –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ (–æ—Å—Ç–∞–µ—Ç—Å—è Gemini)
            Settings.embed_model = GeminiEmbedding(
                model_name=config.EMBEDDING_MODEL, api_key=config.GEMINI_API_KEY
            )
            # –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (—Ç–µ—Å—Ç–∏—Ä—É–µ–º gpt-4o-mini)
            Settings.llm = OpenRouter(
                api_key=config.OPENROUTER_API_KEY,
                model="openai/gpt-4o-mini", # üéØ –ú–û–î–ï–õ–¨ –î–õ–Ø –¢–ï–°–¢–ê!
                max_tokens=2048, # –£–≤–µ–ª–∏—á–∏–º –ª–∏–º–∏—Ç –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                temperature=0.2, # –ß—É—Ç—å –±–æ–ª—å—à–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
            )

            # 2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Pinecone
            pc = pinecone.Pinecone(api_key=config.PINECONE_API_KEY)
            pinecone_index = pc.Index(self.pinecone_index_name)

            # 3. –°–æ–∑–¥–∞–Ω–∏–µ VectorStore –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
            vector_store = PineconeVectorStore(pinecone_index=pinecone_index)
            index = VectorStoreIndex.from_vector_store(vector_store=vector_store)

            # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            reranker = SentenceTransformerRerank(
                model="rerank-english-v1.0", # –ú–æ–¥–µ–ª—å –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
                top_n=4  # –û—Å—Ç–∞–≤–ª—è–µ–º 4 –ª—É—á—à–∏—Ö —á–∞–Ω–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            )

            # 5. –°–æ–∑–¥–∞–Ω–∏–µ Query Engine —Å —Ä–µ—Ä–∞–Ω–∫–µ—Ä–æ–º
            self.query_engine = index.as_query_engine(
                similarity_top_k=15,          # –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º 15 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                node_postprocessors=[reranker] # –ó–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–µ—Ä
            )

            self.logger.info("‚úÖ LlamaIndex RAG —Å–∏—Å—Ç–µ–º–∞ —Å —Ä–µ—Ä–∞–Ω–∫–µ—Ä–æ–º —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (–º–æ–¥–µ–ª—å: gpt-4o-mini)")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LlamaIndex RAG: {e}", exc_info=True)
            raise

    def search_knowledge_base(self, query: str) -> Tuple[str, Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LlamaIndex.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å–æ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–æ–π.
        """
        search_start = time.time()
        if not self.query_engine:
            self.logger.error("LlamaIndex query engine –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            return "–û—à–∏–±–∫–∞: LlamaIndex RAG –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.", {}

        try:
            self.logger.info(f"üîç LlamaIndex RAG: –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
            response = self.query_engine.query(query)

            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–æ–¥
            context_chunks = [node.get_content() for node in response.source_nodes]
            context = "\n\n".join(context_chunks)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞
            search_time = time.time() - search_start
            scores = [node.get_score() for node in response.source_nodes]
            average_score = sum(scores) / len(scores) if scores else 0.0

            metrics = {
                'search_time': search_time,
                'chunks_found': len(context_chunks),
                'average_score': average_score,
                'max_score': max(scores) if scores else 0.0,
            }

            self.logger.info(f"‚úÖ LlamaIndex RAG: –ù–∞–π–¥–µ–Ω–æ {metrics['chunks_found']} —á–∞–Ω–∫–æ–≤ –∑–∞ {search_time:.2f}—Å")
            return context, metrics

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ LlamaIndex RAG: {e}", exc_info=True)
            return f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}", {
                'search_time': time.time() - search_start,
                'chunks_found': 0,
                'average_score': 0.0,
                'fallback_reason': 'llama_index_error'
            }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä LlamaIndex RAG —Å–∏—Å—Ç–µ–º—ã
try:
    llama_index_rag = LlamaIndexRAG()
except Exception as e:
    # –ï—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, —Å–æ–∑–¥–∞–µ–º "–ø—É—Å—Ç—ã—à–∫—É", —á—Ç–æ–±—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —É–ø–∞–ª–æ
    llama_index_rag = None
    logging.getLogger(__name__).critical(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä LlamaIndexRAG: {e}")
