import os
import time
import google.generativeai as genai
from pinecone import Pinecone
from dotenv import load_dotenv
import re
from typing import List, Dict, Optional
from datetime import datetime
import pdfplumber

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_HOST_STYLE = os.getenv("PINECONE_HOST_STYLE")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–ª—é—á–µ–π
if not all([GEMINI_API_KEY, PINECONE_API_KEY, PINECONE_HOST_STYLE]):
    missing = [name for name, value in [
        ('GEMINI_API_KEY', GEMINI_API_KEY),
        ('PINECONE_API_KEY', PINECONE_API_KEY), 
        ('PINECONE_HOST_STYLE', PINECONE_HOST_STYLE)
    ] if not value]
    raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {', '.join(missing)}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini API –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
genai.configure(api_key=GEMINI_API_KEY)

class SimpleZhvanetskyProcessor:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –ñ–≤–∞–Ω–µ—Ü–∫–æ–≥–æ.
    –§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:
    1. –ß—Ç–µ–Ω–∏–µ PDF —Ñ–∞–π–ª–æ–≤
    2. –£–º–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç–∏–ª—è
    3. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ text-embedding-004
    4. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Pinecone
    """
    
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è
        self.min_chunk_size = 300
        self.ideal_chunk_size = 800
        self.max_chunk_size = 1500
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.embedding_model = 'models/text-embedding-004'
        self.delay_between_requests = 0.1  # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ 100ms –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        print("üé≠ –ü–†–û–°–¢–û–ô –ü–†–û–¶–ï–°–°–û–† –¢–ï–ö–°–¢–û–í –ñ–í–ê–ù–ï–¶–ö–û–ì–û")
        print(f"üìù –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤: {self.min_chunk_size}-{self.ideal_chunk_size} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {self.delay_between_requests}—Å")

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        print(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF: {os.path.basename(pdf_path)}")
        
        try:
            extracted_text = ""
            with pdfplumber.open(pdf_path) as pdf:
                total_pages = len(pdf.pages)
                print(f"   üìä –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
                
                for page_num, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        # –ü—Ä–æ—Å—Ç–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
                        cleaned_text = re.sub(r'\n{3,}', '\n\n', page_text)
                        cleaned_text = re.sub(r' {2,}', ' ', cleaned_text)
                        extracted_text += cleaned_text + "\n\n"
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 —Å—Ç—Ä–∞–Ω–∏—Ü
                    if page_num % 50 == 0:
                        print(f"   üìñ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {page_num}/{total_pages}")
                
                print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return extracted_text.strip()
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return ""

    def is_dialogue(self, text: str) -> bool:
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–∞–ª–æ–≥ –≤ —Ç–µ–∫—Å—Ç–µ –ñ–≤–∞–Ω–µ—Ü–∫–æ–≥–æ"""
        dialogue_markers = [
            r'‚Äî\s*[–ê-–Ø–Å]',  # –ü—Ä—è–º–∞—è —Ä–µ—á—å —Å —Ç–∏—Ä–µ
            r'[–ê-–Ø–Å][–∞-—è—ë]*:',  # –ü–µ—Ä—Å–æ–Ω–∞–∂ —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º
            r'–î–∏—Ä–µ–∫—Ç–æ—Ä:',  # –¢–∏–ø–∏—á–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏
            r'–ö–æ—Å—Ç–æ–≥–ª–∞–∑–æ–≤:',
        ]
        
        marker_count = sum(1 for pattern in dialogue_markers if re.search(pattern, text))
        return marker_count >= 2

    def create_chunks(self, content: str, filename: str) -> List[str]:
        """–°–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç–∏–ª—è –ñ–≤–∞–Ω–µ—Ü–∫–æ–≥–æ"""
        print(f"‚úÇÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤: {filename}")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        print(f"   üìÑ –ù–∞–π–¥–µ–Ω–æ –∞–±–∑–∞—Ü–µ–≤: {len(paragraphs)}")
        
        chunks = []
        current_chunk = []
        current_size = 0
        
        for paragraph in paragraphs:
            paragraph_length = len(paragraph)
            
            # –ï—Å–ª–∏ —ç—Ç–æ –¥–∏–∞–ª–æ–≥ –∏ –æ–Ω –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–ª–∏–∫–æ–º
            if self.is_dialogue(paragraph) and paragraph_length <= self.max_chunk_size:
                if current_chunk:
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_size = 0
                
                chunks.append(paragraph)
                print(f"   üí¨ –î–∏–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {paragraph_length} —Å–∏–º–≤–æ–ª–æ–≤")
                continue
            
            # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∞–±–∑–∞—Ü–µ–≤
            potential_size = current_size + paragraph_length + 2  # +2 –¥–ª—è \n\n
            
            if potential_size > self.ideal_chunk_size and current_size >= self.min_chunk_size:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —á–∞–Ω–∫ –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                chunks.append('\n\n'.join(current_chunk))
                current_chunk = [paragraph]
                current_size = paragraph_length
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É —á–∞–Ω–∫—É
                current_chunk.append(paragraph)
                current_size = potential_size
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏
        processed_chunks = []
        for chunk in chunks:
            if len(chunk) < self.min_chunk_size and processed_chunks:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                if len(processed_chunks[-1] + '\n\n' + chunk) <= self.max_chunk_size:
                    processed_chunks[-1] = processed_chunks[-1] + '\n\n' + chunk
                    continue
            
            processed_chunks.append(chunk)
        
        print(f"   üéØ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(processed_chunks)}")
        return processed_chunks

    def generate_safe_id(self, index_name: str, filename: str, chunk_idx: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç ASCII-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π ID –¥–ª—è Pinecone"""
        # –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        transliteration = {
            '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
            '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
            '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
            '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch',
            '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
            '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'Yo',
            '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
            '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
            '–§': 'F', '–•': 'Kh', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Shch',
            '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
        }
        
        # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        clean_filename = os.path.splitext(filename)[0]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
        transliterated = ""
        for char in clean_filename:
            if char in transliteration:
                transliterated += transliteration[char]
            elif char.isalnum() or char in '-_':
                transliterated += char
            elif char in ' .()[]{}':
                transliterated += '-'
        
        # –û—á–∏—â–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        normalized = re.sub(r'-+', '-', transliterated).strip('-')[:50]
        
        return f"{index_name}-{normalized}-{chunk_idx}"

    def vectorize_chunk(self, chunk: str, chunk_id: str) -> Optional[Dict]:
        """–í–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç —á–∞–Ω–∫ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(self.delay_between_requests)
            
            # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            response = genai.embed_content(
                model=self.embedding_model,
                content=chunk,
                task_type="RETRIEVAL_DOCUMENT",
                title="Zhvanetsky Style Sample"
            )
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_type = "dialogue" if self.is_dialogue(chunk) else "narrative"
            
            return {
                "id": chunk_id,
                "values": response['embedding'],
                "metadata": {
                    "text": chunk,
                    "chunk_size": len(chunk),
                    "content_type": content_type,
                    "style_source": "zhvanetsky",
                    "created_at": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ {chunk_id}: {e}")
            return None

    def process_directory(self, directory_path: str, index_name: str) -> Dict:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ñ–∞–π–ª–∞–º–∏ –ñ–≤–∞–Ω–µ—Ü–∫–æ–≥–æ"""
        start_time = time.time()
        
        print(f"\nüé≠ –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–û–í –ñ–í–ê–ù–ï–¶–ö–û–ì–û")
        print(f"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory_path}")
        print(f"üéØ –ò–Ω–¥–µ–∫—Å: {index_name}")
        print("=" * 50)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Pinecone
        try:
            pc = Pinecone(api_key=PINECONE_API_KEY)
            index = pc.Index(host=PINECONE_HOST_STYLE)
            print("üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Pinecone —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Pinecone: {e}")
            return {"success": False, "error": str(e)}
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å
        print("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        index.delete(delete_all=True)
        time.sleep(3)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        try:
            all_files = os.listdir(directory_path)
            supported_files = [f for f in all_files if f.endswith(('.txt', '.pdf'))]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {e}")
            return {"success": False, "error": str(e)}
        
        if not supported_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤")
            return {"success": False, "error": "No files found"}
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(supported_files)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            "files_processed": 0,
            "total_chunks": 0,
            "vectors_uploaded": 0,
            "processing_time": 0,
            "file_details": []
        }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for file_idx, filename in enumerate(supported_files):
            print(f"\nüìñ –§–∞–π–ª {file_idx + 1}/{len(supported_files)}: {filename}")
            file_path = os.path.join(directory_path, filename)
            file_start = time.time()
            
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                if filename.endswith('.pdf'):
                    content = self.extract_text_from_pdf(file_path)
                else:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                
                if len(content) < 100:
                    print(f"   ‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
                chunks = self.create_chunks(content, filename)
                if not chunks:
                    print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏")
                    continue
                
                # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º
                print(f"   üîÑ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è {len(chunks)} —á–∞–Ω–∫–æ–≤...")
                vectors_uploaded = 0
                
                for chunk_idx, chunk in enumerate(chunks):
                    chunk_id = self.generate_safe_id(index_name, filename, chunk_idx)
                    vector_data = self.vectorize_chunk(chunk, chunk_id)
                    
                    if vector_data:
                        index.upsert(vectors=[vector_data])
                        vectors_uploaded += 1
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        if (chunk_idx + 1) % 10 == 0:
                            print(f"      üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {chunk_idx + 1}/{len(chunks)}")
                
                file_time = time.time() - file_start
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ñ–∞–π–ª–∞
                file_stat = {
                    "filename": filename,
                    "chunks_created": len(chunks),
                    "vectors_uploaded": vectors_uploaded,
                    "processing_time": file_time
                }
                
                stats["file_details"].append(file_stat)
                stats["files_processed"] += 1
                stats["total_chunks"] += len(chunks)
                stats["vectors_uploaded"] += vectors_uploaded
                
                print(f"   ‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {file_time:.1f}—Å")
                print(f"      üì¶ –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
                print(f"      üíæ –í–µ–∫—Ç–æ—Ä–æ–≤: {vectors_uploaded}")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = time.time() - start_time
        stats["processing_time"] = total_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Pinecone
        time.sleep(3)
        final_stats = index.describe_index_stats()
        
        print(f"\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("=" * 40)
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   üìÅ –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['files_processed']}")
        print(f"   üìù –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats['total_chunks']}")
        print(f"   üíæ –í–µ–∫—Ç–æ—Ä–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {stats['vectors_uploaded']}")
        print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–æ–≤ –≤ Pinecone: {final_stats.total_vector_count}")
        
        return {"success": True, "stats": stats}

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    processor = SimpleZhvanetskyProcessor()
    result = processor.process_directory("data_style", "ukido-style")
    
    if result["success"]:
        print("\n‚ú® –¢–µ–∫—Å—Ç—ã –ñ–≤–∞–Ω–µ—Ü–∫–æ–≥–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        print("üé≠ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ –≤ —Å—Ç–∏–ª–µ –≤–µ–ª–∏–∫–æ–≥–æ —Å–∞—Ç–∏—Ä–∏–∫–∞")
    else:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    main()