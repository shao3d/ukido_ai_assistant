# rag_system.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG (Retrieval-Augmented Generation) —Å–∏—Å—Ç–µ–º–æ–π.
–ü—Ä–æ—Å—Ç–∞—è, –Ω–∞–¥–µ–∂–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –∏–∑–ª–∏—à–Ω–∏—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π.
"""

import time
import hashlib
import threading
import logging
from typing import Tuple, Dict, Any, Optional, List

import google.generativeai as genai
from pinecone import Pinecone

from config import config


class RAGSystem:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG —Å–∏—Å—Ç–µ–º–æ–π.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Google Gemini
        genai.configure(api_key=config.GEMINI_API_KEY)
        self.embedding_model = config.EMBEDDING_MODEL
        
        # Pinecone –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.pinecone_index = None
        self.pinecone_available = False
        
        # –ü—Ä–æ—Å—Ç–æ–π –∫–µ—à
        self.rag_cache = {}
        
        self.logger.info("üîç RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    def _rerank_chunks_by_keywords(self, query: str, matches: list) -> list:
        """
        –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –ø–æ –Ω–∞–ª–∏—á–∏—é –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞.
        """
        query_words = query.lower().split()
        scored_matches = []
        for match in matches:
            chunk_text = match.metadata.get('text', '').lower()
            keyword_score = 0
            for word in query_words:
                if len(word) > 3:
                    keyword_score += chunk_text.count(word)
            if "–¥–º–∏—Ç—Ä–∏–π" in query_words and "–¥–º–∏—Ç—Ä–∏–π" in chunk_text:
                keyword_score += 5
            if "–ø–µ—Ç—Ä–æ–≤" in query_words and "–ø–µ—Ç—Ä–æ–≤" in chunk_text:
                keyword_score += 5
            scored_matches.append((match, keyword_score))
        scored_matches.sort(key=lambda x: (x[1], x[0].score), reverse=True)
        return [match for match, _ in scored_matches]

    def _extract_relevant_sentences(self, chunk_text: str, query: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ —á–∞–Ω–∫–∞.
        """
        sentences = chunk_text.split('.')
        query_words = set(word.lower() for word in query.split() if len(word) > 3)
        relevant_sentences = []
        for sentence in sentences:
            sentence_lower = sentence.lower()
            if any(word in sentence_lower for word in query_words):
                relevant_sentences.append(sentence.strip())
        if not relevant_sentences and sentences:
            relevant_sentences = sentences[:2]
        return '. '.join(relevant_sentences) + '.'

    def _get_pinecone_index(self):
        """
        –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone.
        """
        if self.pinecone_index is not None:
            return self.pinecone_index
        
        try:
            self.logger.info("üîå –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Pinecone...")
            pc = Pinecone(api_key=config.PINECONE_API_KEY)
            
            try:
                facts_description = pc.describe_index("ukido")
                self.pinecone_index = pc.Index(host=facts_description.host)
                self.logger.info("‚úÖ Pinecone –ø–æ–¥–∫–ª—é—á–µ–Ω")
            except:
                self.pinecone_index = pc.Index(host=config.PINECONE_HOST_FACTS)
                self.logger.info("‚úÖ Pinecone –ø–æ–¥–∫–ª—é—á–µ–Ω (fallback)")
            
            self.pinecone_available = True
            return self.pinecone_index
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ Pinecone: {e}")
            self.pinecone_available = False
            return None

    def _get_embedding(self, text: str) -> Optional[List[float]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ Gemini API.
        """
        try:
            result = genai.embed_content(
                model=self.embedding_model,
                content=text,
                task_type="retrieval_query"
            )
            return result['embedding']
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ Gemini API: {e}")
            return None

    def search_knowledge_base(self, query: str, conversation_history: List[str] = None) -> Tuple[str, Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π - –ø—Ä–æ—Å—Ç–∞—è –∏ –Ω–∞–¥–µ–∂–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è.
        """
        search_start = time.time()
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
        cache_key = hashlib.md5(query.encode()).hexdigest()
        if cache_key in self.rag_cache:
            cached_entry = self.rag_cache[cache_key]
            if time.time() - cached_entry['timestamp'] < 300:  # 5 –º–∏–Ω—É—Ç TTL
                return cached_entry['result']
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            query_embedding = self._get_embedding(query)
            if query_embedding is None:
                return self._fallback_response("embedding_error", search_start)
            
            # –ü–æ–ª—É—á–∞–µ–º Pinecone –∏–Ω–¥–µ–∫—Å
            index = self._get_pinecone_index()
            if index is None:
                return self._fallback_response("pinecone_error", search_start)
            
            # –ü—Ä–æ—Å—Ç–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤ –ë–ï–ó —Å–∂–∞—Ç–∏—è
            search_results = index.query(
                vector=query_embedding,
                top_k=10,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å 8 –¥–æ 10
                include_metadata=True
            )
            
            if not search_results.matches:
                return self._fallback_response("no_results", search_start)
            
            # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —á–∞–Ω–∫–∏ –±–µ–∑ —Å–∂–∞—Ç–∏—è
            relevant_chunks = []
            for match in search_results.matches:
                chunk_text = match.metadata.get('text', '')
                if chunk_text:
                    relevant_chunks.append(chunk_text)
            
            context = '\n\n'.join(relevant_chunks) if relevant_chunks else "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
            metrics = {
                'search_time': time.time() - search_start,
                'chunks_found': len(relevant_chunks),
                'max_score': max([m.score for m in top_matches]) if top_matches else 0
            }
            
            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = (context, metrics)
            self.rag_cache[cache_key] = {
                'result': result,
                'timestamp': time.time()
            }
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–µ—à–∞
            if len(self.rag_cache) > 100:
                oldest_keys = list(self.rag_cache.keys())[:20]
                for key in oldest_keys:
                    del self.rag_cache[key]
            
            self.logger.info(f"üîç RAG –ø–æ–∏—Å–∫: {len(relevant_chunks)} —á–∞–Ω–∫–æ–≤ –∑–∞ {metrics['search_time']:.2f}—Å")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ RAG: {e}")
            return self._fallback_response("critical_error", search_start)

    def _fallback_response(self, reason: str, search_start: float) -> Tuple[str, Dict[str, Any]]:
        """
        –ü—Ä–æ—Å—Ç–æ–π fallback –æ—Ç–≤–µ—Ç.
        """
        context = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        metrics = {
            'search_time': time.time() - search_start,
            'chunks_found': 0,
            'fallback_reason': reason
        }
        return context, metrics

    def get_stats(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞.
        """
        return {
            "cache_size": len(self.rag_cache),
            "pinecone_available": self.pinecone_available
        }


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä RAG —Å–∏—Å—Ç–µ–º—ã
rag_system = RAGSystem()