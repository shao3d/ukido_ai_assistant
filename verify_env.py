# verify_env.py
"""
Простой скрипт для проверки, может ли Python в текущем окружении
найти и импортировать проблемный модуль LlamaIndex.
"""
import sys

print("--- ДИАГНОСТИКА ОКРУЖЕНИЯ ---")
print(f"Используется Python: {sys.executable}")
print(f"Версия Python: {sys.version}")
print("-" * 30)

try:
    # Пытаемся импортировать именно тот модуль, на который ругается app.py
    from llama_index.llms.gemini import Gemini
    
    # Если импорт прошел успешно, выводим сообщение об успехе
    print("\n✅ УСПЕХ! Модуль 'llama_index.llms.gemini' успешно найден и импортирован.")
    print("Это означает, что ваше виртуальное окружение (venv) настроено ПРАВИЛЬНО.")
    print("Проблема, скорее всего, в том, как VS Code запускает основной скрипт app.py.")

except ImportError as e:
    # Если импорт не удался, выводим сообщение об ошибке
    print(f"\n❌ ПРОВАЛ! Не удалось импортировать модуль.")
    print(f"Ошибка: {e}")
    print("Это означает, что проблема в самом виртуальном окружении или в установке Python.")
    print("Пожалуйста, покажите этот вывод ассистенту.")

except Exception as e:
    print(f"\n❌ Неожиданная ошибка: {e}")

print("\n--- ДИАГНОСТИКА ЗАВЕРШЕНА ---")

