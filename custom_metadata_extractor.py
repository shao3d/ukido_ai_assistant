"""
–ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è LlamaIndex
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ node.text –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
–¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –≤ RAG —Å–∏—Å—Ç–µ–º–µ.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é extract_metadata() —Å —Ç–æ–ø-10 –ø–æ–ª—è–º–∏.
"""

import re
import logging
from typing import List, Dict, Any, Optional, Sequence
from llama_index.core.extractors import BaseExtractor
from llama_index.core.schema import BaseNode
from extract_metadata import extract_metadata

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

class CustomMetadataExtractor(BaseExtractor):
    """
    –ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —É–∑–ª–æ–≤
    –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—è –∫–ª–∞—Å—Å–∞ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    courses: Dict[str, List[str]] = {}
    content_patterns: Dict[str, List[str]] = {}
    pricing_patterns: List[str] = []
    teacher_patterns: List[str] = []
    faq_patterns: List[str] = []
    teacher_names: List[str] = []
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞"""
        super().__init__()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—É—Ä—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
        self.courses = {
            "–ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤": ["–ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤", "–ö–∞–ø–∏—Ç–∞–Ω", "–∫–∞–ø–∏—Ç–∞–Ω –ø—Ä–æ–µ–∫—Ç–æ–≤", "–∫–∞–ø–∏—Ç–∞–Ω"],
            "–Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä": ["–Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä", "–û—Ä–∞—Ç–æ—Ä", "—é–Ω—ã–π –æ—Ä–∞—Ç–æ—Ä", "–æ—Ä–∞—Ç–æ—Ä"],
            "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ö–æ–º–ø–∞—Å": ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ö–æ–º–ø–∞—Å", "–ö–æ–º–ø–∞—Å", "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–º–ø–∞—Å", "–∫–æ–º–ø–∞—Å"]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.content_patterns = {
            "pricing": [
                r"–≥—Ä–Ω",
                r"–æ–ø–ª–∞—Ç",
                r"—Å—Ç–æ–∏–º–æ—Å—Ç",
                r"—Ü–µ–Ω",
                r"—Å–∫–∏–¥–∫",
                r"—Ç–∞—Ä–∏—Ñ",
                r"—Ä—É–±",
                r"‚Ç¥",
                r"‚ÇΩ"
            ],
            "teachers": [
                r"–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø",
                r"–û–ü–´–¢ –†–ê–ë–û–¢–´",
                r"–û–ë–†–ê–ó–û–í–ê–ù–ò–ï:",
                r"–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å",
                r"—Ç—Ä–µ–Ω–µ—Ä",
                r"–º–µ–Ω—Ç–æ—Ä"
            ],
            "faq": [
                r"Q:",
                r"A:",
                r"–í–æ–ø—Ä–æ—Å:",
                r"–û—Ç–≤–µ—Ç:",
                r"–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ",
                r"FAQ"
            ],
            "schedule": [
                r"—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ",
                r"–≤—Ä–µ–º—è",
                r"–¥–∞—Ç–∞",
                r"–∑–∞–Ω—è—Ç–∏–µ",
                r"—É—Ä–æ–∫",
                r"—á–∞—Å"
            ],
            "course_description": [
                r"–ø—Ä–æ–≥—Ä–∞–º–º–∞",
                r"–∫—É—Ä—Å",
                r"–æ–±—É—á–µ–Ω–∏–µ",
                r"–º–æ–¥—É–ª—å",
                r"—É—Ä–æ–∫"
            ]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.pricing_patterns = [
            r"–≥—Ä–Ω",
            r"–æ–ø–ª–∞—Ç",
            r"—Å—Ç–æ–∏–º–æ—Å—Ç",
            r"—Ü–µ–Ω",
            r"—Å–∫–∏–¥–∫"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è—Ö
        self.teacher_patterns = [
            r"–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø",
            r"–û–ü–´–¢ –†–ê–ë–û–¢–´",
            r"–û–ë–†–ê–ó–û–í–ê–ù–ò–ï:",
            r"–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å",
            r"—Ç—Ä–µ–Ω–µ—Ä",
            r"–º–µ–Ω—Ç–æ—Ä"
        ]
        
        # –ò–º–µ–Ω–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.teacher_names = [
            "–ê–Ω–Ω–∞ –ö–æ–≤–∞–ª–µ–Ω–∫–æ",
            "–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤", 
            "–ï–ª–µ–Ω–∞ –°–∏–¥–æ—Ä–æ–≤–∞"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è FAQ
        self.faq_patterns = [
            r"Q:",
            r"A:",
            r"–í–æ–ø—Ä–æ—Å:",
            r"–û—Ç–≤–µ—Ç:"
        ]
        
        logger.info("‚úÖ CustomMetadataExtractor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π extract_metadata()")
    
    def _determine_content_type(self, text: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        """
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        for content_type, patterns in self.content_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    return content_type
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π —Ç–∏–ø
        return "general"
    
    def _has_pricing_info(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        """
        text_lower = text.lower()
        
        for pattern in self.pricing_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        return False
    
    def _find_mentioned_courses(self, text: str) -> List[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫—É—Ä—Å–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫ –∏ —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        mentioned_courses = []
        
        for course_name, search_variants in self.courses.items():
            found = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫—É—Ä—Å–∞
            for variant in search_variants:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å—Ç—å –ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç –≤ —Ç–µ–∫—Å—Ç–µ (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
                if variant.lower() in text.lower():
                    found = True
                    break
                    
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –∫–∞–≤—ã—á–∫–∞–º–∏
                if f'"{variant}"' in text or f"'{variant}'" in text:
                    found = True
                    break
                    
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏
                if f'¬´{variant}¬ª' in text:
                    found = True
                    break
            
            if found and course_name not in mentioned_courses:
                mentioned_courses.append(course_name)
        
        return mentioned_courses
    
    def _is_teacher_info(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è—Ö
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.teacher_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–µ–Ω–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π
        for teacher_name in self.teacher_names:
            if re.search(re.escape(teacher_name), text, re.IGNORECASE):
                return True
        
        return False
    
    def _is_faq(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç FAQ
        """
        for pattern in self.faq_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        return False
    
    def _extract_metadata_from_text(self, text: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —É–∑–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—è –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é extract_metadata()
        —Å —Ç–æ–ø-10 –ø–æ–ª—è–º–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        extracted_metadata = extract_metadata(text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –ø–æ–ª—è–º–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        legacy_metadata = {}
        
        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π –Ω–∞ —Å—Ç–∞—Ä—ã–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        legacy_metadata["content_type"] = extracted_metadata.get("content_category", "general")
        legacy_metadata["has_pricing"] = extracted_metadata.get("has_pricing", False)
        legacy_metadata["course_mentioned"] = extracted_metadata.get("courses_offered", [])
        legacy_metadata["is_teacher_info"] = False  # –£–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–µ
        legacy_metadata["is_faq"] = extracted_metadata.get("content_category") == "FAQ"
        legacy_metadata["text_length"] = len(text)
        legacy_metadata["has_courses"] = len(legacy_metadata["course_mentioned"]) > 0
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—ã–µ –∏ —Å—Ç–∞—Ä—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        combined_metadata = {**extracted_metadata, **legacy_metadata}
        
        return combined_metadata
    
    def extract(self, nodes: Sequence[BaseNode]) -> List[Dict[str, Any]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–ø–∏—Å–∫–∞ —É–∑–ª–æ–≤
        
        Args:
            nodes: –°–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞
        """
        metadata_list = []
        
        logger.info(f"üîç –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ {len(nodes)} —É–∑–ª–æ–≤")
        
        for i, node in enumerate(nodes):
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —É–∑–ª–∞
                text = getattr(node, 'text', '')
                
                if not text:
                    logger.warning(f"‚ö†Ô∏è –£–∑–µ–ª {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                    metadata_list.append({})
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                extracted_metadata = self._extract_metadata_from_text(text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—É—Ä—Å—ã –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –≤–æ–ø—Ä–æ—Å–∞—Ö)
                existing_metadata = getattr(node, 'metadata', {})
                if existing_metadata:
                    # –ò—â–µ–º –∫—É—Ä—Å—ã –≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—è—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    for key, value in existing_metadata.items():
                        if isinstance(value, (str, list)):
                            # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                            search_text = ' '.join(value) if isinstance(value, list) else value
                            # –ù–∞—Ö–æ–¥–∏–º –∫—É—Ä—Å—ã –≤ —ç—Ç–æ–º —Ç–µ–∫—Å—Ç–µ
                            additional_courses = self._find_mentioned_courses(search_text)
                            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫—É—Ä—Å—ã –∫ –æ—Å–Ω–æ–≤–Ω—ã–º
                            for course in additional_courses:
                                if course not in extracted_metadata["course_mentioned"]:
                                    extracted_metadata["course_mentioned"].append(course)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º has_courses –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫—É—Ä—Å–æ–≤
                    extracted_metadata["has_courses"] = len(extracted_metadata["course_mentioned"]) > 0
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º —É–∑–ª–∞
                if hasattr(node, 'metadata') and node.metadata:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º–∏
                    node.metadata.update(extracted_metadata)
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    node.metadata = extracted_metadata
                
                metadata_list.append(extracted_metadata)
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —É–∑–ª–æ–≤ (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è)
                if i < 3:
                    key_fields = {
                        "content_category": extracted_metadata.get("content_category"),
                        "pricing_info": extracted_metadata.get("has_pricing", False),
                        "special_needs": extracted_metadata.get("has_special_needs_info", False),
                        "courses": extracted_metadata.get("courses_offered", []),
                        "age_groups": extracted_metadata.get("age_groups_mentioned", [])
                    }
                    logger.info(f"‚úÖ –£–∑–µ–ª {i}: {key_fields}")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —É–∑–ª–∞ {i}: {e}")
                metadata_list.append({})
        
        logger.info(f"üéâ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(nodes)} —É–∑–ª–æ–≤")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_types = {}
        for metadata in metadata_list:
            content_type = metadata.get("content_type", "unknown")
            content_types[content_type] = content_types.get(content_type, 0) + 1
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_types}")
        
        return metadata_list
    
    async def aextract(self, nodes: Sequence[BaseNode]) -> List[Dict[str, Any]]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è extract - –ø—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é"""
        return self.extract(nodes)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def create_custom_metadata_extractor():
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
    """
    return CustomMetadataExtractor()

# –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    extractor = CustomMetadataExtractor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    test_texts = [
        "–ö—É—Ä—Å –ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤ —Å—Ç–æ–∏—Ç 6000 –≥—Ä–Ω. –°–µ–º–µ–π–Ω–∞—è —Å–∫–∏–¥–∫–∞ 15% –¥–ª—è –¥–≤—É—Ö –¥–µ—Ç–µ–π.",
        "–î–ª—è –¥–µ—Ç–µ–π —Å –°–î–í–ì –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –±–ª–æ–∫–∏ 5-7 –º–∏–Ω—É—Ç –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏.",
        "–°—ã–Ω —É–≤–ª–µ–∫–∞–µ—Ç—Å—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫—É—Ä—Å –ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è –≤–æ–∑—Ä–∞—Å—Ç–∞ 11-14 –ª–µ—Ç.",
        "–ê–Ω–Ω–∞ –ö–æ–≤–∞–ª–µ–Ω–∫–æ –≤–µ–¥–µ—Ç –∫—É—Ä—Å –Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä –¥–ª—è –¥–µ—Ç–µ–π 7-10 –ª–µ—Ç. –û–ø—ã—Ç 8 –ª–µ—Ç."
    ]
    
    # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ-—É–∑–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    class TestNode:
        def __init__(self, text):
            self.text = text
            self.metadata = {}
    
    test_nodes = [TestNode(text) for text in test_texts]
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    results = extractor.extract(test_nodes)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    for i, (text, metadata) in enumerate(zip(test_texts, results)):
        print(f"\n--- –¢–µ—Å—Ç {i+1} ---")
        print(f"–¢–µ–∫—Å—Ç: {text[:50]}...")
        print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}")