"""
–ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è LlamaIndex
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ node.text –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
–¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –≤ RAG —Å–∏—Å—Ç–µ–º–µ.
"""

import re
import logging
from typing import List, Dict, Any, Optional, Sequence
from llama_index.core.extractors import BaseExtractor
from llama_index.core.schema import BaseNode

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

class CustomMetadataExtractor(BaseExtractor):
    """
    –ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —É–∑–ª–æ–≤
    –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—è –∫–ª–∞—Å—Å–∞ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    courses: Dict[str, List[str]] = {}
    content_patterns: Dict[str, List[str]] = {}
    pricing_patterns: List[str] = []
    teacher_patterns: List[str] = []
    faq_patterns: List[str] = []
    teacher_names: List[str] = []
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞"""
        super().__init__()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—É—Ä—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
        self.courses = {
            "–ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤": ["–ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤", "–ö–∞–ø–∏—Ç–∞–Ω", "–∫–∞–ø–∏—Ç–∞–Ω –ø—Ä–æ–µ–∫—Ç–æ–≤", "–∫–∞–ø–∏—Ç–∞–Ω"],
            "–Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä": ["–Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä", "–û—Ä–∞—Ç–æ—Ä", "—é–Ω—ã–π –æ—Ä–∞—Ç–æ—Ä", "–æ—Ä–∞—Ç–æ—Ä"],
            "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ö–æ–º–ø–∞—Å": ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ö–æ–º–ø–∞—Å", "–ö–æ–º–ø–∞—Å", "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–º–ø–∞—Å", "–∫–æ–º–ø–∞—Å"]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.content_patterns = {
            "pricing": [
                r"–≥—Ä–Ω",
                r"–æ–ø–ª–∞—Ç",
                r"—Å—Ç–æ–∏–º–æ—Å—Ç",
                r"—Ü–µ–Ω",
                r"—Å–∫–∏–¥–∫",
                r"—Ç–∞—Ä–∏—Ñ",
                r"—Ä—É–±",
                r"‚Ç¥",
                r"‚ÇΩ"
            ],
            "teachers": [
                r"–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø",
                r"–û–ü–´–¢ –†–ê–ë–û–¢–´",
                r"–û–ë–†–ê–ó–û–í–ê–ù–ò–ï:",
                r"–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å",
                r"—Ç—Ä–µ–Ω–µ—Ä",
                r"–º–µ–Ω—Ç–æ—Ä"
            ],
            "faq": [
                r"Q:",
                r"A:",
                r"–í–æ–ø—Ä–æ—Å:",
                r"–û—Ç–≤–µ—Ç:",
                r"–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ",
                r"FAQ"
            ],
            "schedule": [
                r"—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ",
                r"–≤—Ä–µ–º—è",
                r"–¥–∞—Ç–∞",
                r"–∑–∞–Ω—è—Ç–∏–µ",
                r"—É—Ä–æ–∫",
                r"—á–∞—Å"
            ],
            "course_description": [
                r"–ø—Ä–æ–≥—Ä–∞–º–º–∞",
                r"–∫—É—Ä—Å",
                r"–æ–±—É—á–µ–Ω–∏–µ",
                r"–º–æ–¥—É–ª—å",
                r"—É—Ä–æ–∫"
            ]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.pricing_patterns = [
            r"–≥—Ä–Ω",
            r"–æ–ø–ª–∞—Ç",
            r"—Å—Ç–æ–∏–º–æ—Å—Ç",
            r"—Ü–µ–Ω",
            r"—Å–∫–∏–¥–∫"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è—Ö
        self.teacher_patterns = [
            r"–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø",
            r"–û–ü–´–¢ –†–ê–ë–û–¢–´",
            r"–û–ë–†–ê–ó–û–í–ê–ù–ò–ï:",
            r"–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å",
            r"—Ç—Ä–µ–Ω–µ—Ä",
            r"–º–µ–Ω—Ç–æ—Ä"
        ]
        
        # –ò–º–µ–Ω–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.teacher_names = [
            "–ê–Ω–Ω–∞ –ö–æ–≤–∞–ª–µ–Ω–∫–æ",
            "–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤", 
            "–ï–ª–µ–Ω–∞ –°–∏–¥–æ—Ä–æ–≤–∞"
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è FAQ
        self.faq_patterns = [
            r"Q:",
            r"A:",
            r"–í–æ–ø—Ä–æ—Å:",
            r"–û—Ç–≤–µ—Ç:"
        ]
        
        logger.info("‚úÖ CustomMetadataExtractor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _determine_content_type(self, text: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        """
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        for content_type, patterns in self.content_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    return content_type
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π —Ç–∏–ø
        return "general"
    
    def _has_pricing_info(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        """
        text_lower = text.lower()
        
        for pattern in self.pricing_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        return False
    
    def _find_mentioned_courses(self, text: str) -> List[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫—É—Ä—Å–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫ –∏ —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        mentioned_courses = []
        
        for course_name, search_variants in self.courses.items():
            found = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫—É—Ä—Å–∞
            for variant in search_variants:
                # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –±–µ–∑
                patterns = [
                    rf'["\']?{re.escape(variant)}["\']?',  # –° –∫–∞–≤—ã—á–∫–∞–º–∏ –∏–ª–∏ –±–µ–∑
                    rf'{re.escape(variant)}',              # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                ]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
                for pattern in patterns:
                    if re.search(pattern, text, re.IGNORECASE):
                        found = True
                        break
                
                if found:
                    break
            
            if found and course_name not in mentioned_courses:
                mentioned_courses.append(course_name)
        
        return mentioned_courses
    
    def _is_teacher_info(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è—Ö
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.teacher_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–µ–Ω–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π
        for teacher_name in self.teacher_names:
            if re.search(re.escape(teacher_name), text, re.IGNORECASE):
                return True
        
        return False
    
    def _is_faq(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç FAQ
        """
        for pattern in self.faq_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        return False
    
    def _extract_metadata_from_text(self, text: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —É–∑–ª–∞
        """
        metadata = {}
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        metadata["content_type"] = self._determine_content_type(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        metadata["has_pricing"] = self._has_pricing_info(text)
        
        # –ù–∞—Ö–æ–¥–∏–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫—É—Ä—Å–æ–≤
        metadata["course_mentioned"] = self._find_mentioned_courses(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è—Ö
        metadata["is_teacher_info"] = self._is_teacher_info(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ FAQ
        metadata["is_faq"] = self._is_faq(text)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata["text_length"] = len(text)
        metadata["has_courses"] = len(metadata["course_mentioned"]) > 0
        
        return metadata
    
    def extract(self, nodes: Sequence[BaseNode]) -> List[Dict[str, Any]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–ø–∏—Å–∫–∞ —É–∑–ª–æ–≤
        
        Args:
            nodes: –°–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞
        """
        metadata_list = []
        
        logger.info(f"üîç –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ {len(nodes)} —É–∑–ª–æ–≤")
        
        for i, node in enumerate(nodes):
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —É–∑–ª–∞
                text = getattr(node, 'text', '')
                
                if not text:
                    logger.warning(f"‚ö†Ô∏è –£–∑–µ–ª {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                    metadata_list.append({})
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                extracted_metadata = self._extract_metadata_from_text(text)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º —É–∑–ª–∞
                if hasattr(node, 'metadata') and node.metadata:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º–∏
                    node.metadata.update(extracted_metadata)
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    node.metadata = extracted_metadata
                
                metadata_list.append(extracted_metadata)
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —É–∑–ª–æ–≤
                if i < 3:
                    logger.info(f"‚úÖ –£–∑–µ–ª {i}: {extracted_metadata}")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —É–∑–ª–∞ {i}: {e}")
                metadata_list.append({})
        
        logger.info(f"üéâ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(nodes)} —É–∑–ª–æ–≤")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_types = {}
        for metadata in metadata_list:
            content_type = metadata.get("content_type", "unknown")
            content_types[content_type] = content_types.get(content_type, 0) + 1
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_types}")
        
        return metadata_list
    
    async def aextract(self, nodes: Sequence[BaseNode]) -> List[Dict[str, Any]]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è extract - –ø—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é"""
        return self.extract(nodes)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def create_custom_metadata_extractor():
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
    """
    return CustomMetadataExtractor()

# –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    extractor = CustomMetadataExtractor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        "–ö—É—Ä—Å –ö–∞–ø–∏—Ç–∞–Ω –ü—Ä–æ–µ–∫—Ç–æ–≤ —Å—Ç–æ–∏—Ç 2500 –≥—Ä–Ω. –°–∫–∏–¥–∫–∞ 20% –¥–ª—è —Ä–∞–Ω–Ω–∏—Ö —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π.",
        "–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø: –ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∏–º–µ–µ—Ç 10 –ª–µ—Ç –æ–ø—ã—Ç–∞. –û–ë–†–ê–ó–û–í–ê–ù–ò–ï: –ú–∞–≥–∏—Å—Ç—Ä –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏.",
        "Q: –°–∫–æ–ª—å–∫–æ –¥–ª–∏—Ç—Å—è –∫—É—Ä—Å –Æ–Ω—ã–π –û—Ä–∞—Ç–æ—Ä? A: –ö—É—Ä—Å –¥–ª–∏—Ç—Å—è 8 –Ω–µ–¥–µ–ª—å.",
        "–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∫—É—Ä—Å–∞ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ö–æ–º–ø–∞—Å –≤–∫–ª—é—á–∞–µ—Ç 12 –º–æ–¥—É–ª–µ–π –æ–±—É—á–µ–Ω–∏—è."
    ]
    
    # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ-—É–∑–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    class TestNode:
        def __init__(self, text):
            self.text = text
            self.metadata = {}
    
    test_nodes = [TestNode(text) for text in test_texts]
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    results = extractor.extract(test_nodes)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    for i, (text, metadata) in enumerate(zip(test_texts, results)):
        print(f"\n--- –¢–µ—Å—Ç {i+1} ---")
        print(f"–¢–µ–∫—Å—Ç: {text[:50]}...")
        print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}")