# intelligent_analyzer.py (Production Ready)
"""
PRODUCTION-READY –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
1. Thread-safe –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö cache –æ–ø–µ—Ä–∞—Ü–∏–π
2. Proper resource management —Å –ª–∏–º–∏—Ç–∞–º–∏ –ø–∞–º—è—Ç–∏
3. Graceful degradation –∏ error handling
4. Memory cleanup –∏ garbage collection
5. Safe shutdown –º–µ—Ö–∞–Ω–∏–∑–º—ã
"""

import logging
import hashlib
import time
import threading
import atexit
import weakref
from typing import Tuple, List, Optional, Dict, Any
from collections import defaultdict, deque
import json
import re
from config import config


class ProductionHotPathOptimizer:
    """
    Production-ready –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    
    def __init__(self):
        # Thread-safe —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞—Å—Ç–æ—Ç—ã –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.pattern_frequency = defaultdict(int)
        self.hot_patterns = {}
        self.stats_lock = threading.Lock()
        
        # –õ–∏–º–∏—Ç—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è memory leak
        self.max_pattern_entries = 500
        self.max_hot_patterns = 50
        
        # –ü—Ä–µ–¥–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ regex –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        self.quick_patterns = {
            'price_question': re.compile(r'\b(—Ü–µ–Ω|—Å—Ç–æ–∏–º–æ—Å—Ç—å|—Å–∫–æ–ª—å–∫–æ|–¥–æ—Ä–æ–≥–æ|–¥–µ—à–µ–≤–æ)\b', re.I),
            'age_question': re.compile(r'\b(–≤–æ–∑—Ä–∞—Å—Ç|–ª–µ—Ç|–≥–æ–¥–∏–∫|—Ä–µ–±–µ–Ω–∫)\b', re.I),
            'schedule_question': re.compile(r'\b(—Ä–∞—Å–ø–∏—Å–∞–Ω|–≤—Ä–µ–º—è|–∫–æ–≥–¥–∞|–≥—Ä–∞—Ñ–∏–∫)\b', re.I),
            'trial_request': re.compile(r'\b(–ø—Ä–æ–±–Ω|–ø–æ–ø—Ä–æ–±–æ–≤–∞|–±–µ—Å–ø–ª–∞—Ç–Ω|–∑–∞–ø–∏—Å–∞)\b', re.I),
        }
        
        # –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è hot patterns
        self.instant_classifications = {
            'price_question': ('factual', 'fact_finding'),
            'age_question': ('factual', 'fact_finding'), 
            'schedule_question': ('factual', 'fact_finding'),
            'trial_request': ('factual', 'closing'),
        }
        
        self.logger = logging.getLogger(f"{__name__}.HotPath")
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º cleanup
        atexit.register(self.cleanup)
    
    def quick_classify(self, user_message: str) -> Optional[Tuple[str, str]]:
        """
        Thread-safe –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –≥–æ—Ä—è—á–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        message_lower = user_message.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–¥–æ 15 —Å–ª–æ–≤)
        if len(user_message.split()) > 15:
            return None
        
        for pattern_name, regex in self.quick_patterns.items():
            if regex.search(message_lower):
                # Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                with self.stats_lock:
                    self.pattern_frequency[pattern_name] += 1
                    self._cleanup_patterns_if_needed()
                
                classification = self.instant_classifications[pattern_name]
                self.logger.info(f"‚ö° Hot path classification: {pattern_name} -> {classification}")
                return classification
        
        return None
    
    def _cleanup_patterns_if_needed(self):
        """Thread-safe cleanup –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è memory leak"""
        if len(self.pattern_frequency) > self.max_pattern_entries:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            sorted_patterns = sorted(self.pattern_frequency.items(), 
                                   key=lambda x: x[1], reverse=True)
            
            # –û—á–∏—â–∞–µ–º –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø 50%
            self.pattern_frequency.clear()
            keep_count = self.max_pattern_entries // 2
            
            for pattern, count in sorted_patterns[:keep_count]:
                self.pattern_frequency[pattern] = count
            
            self.logger.info(f"üßπ Pattern cleanup: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {keep_count} —Ç–æ–ø –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
    
    def update_hot_patterns(self):
        """Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≥–æ—Ä—è—á–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        with self.stats_lock:
            total_requests = sum(self.pattern_frequency.values())
            if total_requests % 50 == 0 and total_requests > 0:
                sorted_patterns = sorted(self.pattern_frequency.items(), 
                                       key=lambda x: x[1], reverse=True)
                
                self.logger.info(f"üìä Updated hot patterns: {sorted_patterns[:5]}")
    
    def cleanup(self):
        """Cleanup —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            with self.stats_lock:
                self.pattern_frequency.clear()
                self.hot_patterns.clear()
            self.logger.info("üßπ HotPath optimizer cleanup completed")
        except Exception as e:
            self.logger.error(f"HotPath cleanup error: {e}")


class MicroPromptBuilder:
    """
    –°—Ç—Ä–æ–∏—Ç–µ–ª—å –º–∏–∫—Ä–æ-–ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ LLM
    """
    
    @staticmethod
    def build_micro_category_prompt(user_message: str) -> str:
        """–£–ª—å—Ç—Ä–∞-–∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ 70%)"""
        short_message = user_message[:200] + "..." if len(user_message) > 200 else user_message
        
        return f"""Categorize quickly:
"{short_message}"

Output only one word:
factual (prices/courses/schedule)  
philosophical (parenting thoughts)
problem_solving (child issues)
sensitive (illness/death/trauma)

Answer:"""

    @staticmethod
    def build_micro_state_prompt(user_message: str, current_state: str) -> str:
        """–£–ª—å—Ç—Ä–∞-–∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ª–∏–¥–∞"""
        short_message = user_message[:150] + "..." if len(user_message) > 150 else user_message
        
        return f"""Lead state for: "{short_message}"
Current: {current_state}

Output only one word:
greeting/fact_finding/problem_solving/closing

Answer:"""

    @staticmethod  
    def build_combined_micro_prompt(user_message: str, current_state: str) -> str:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –º–∏–∫—Ä–æ-–ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ + —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        short_message = user_message[:180] + "..." if len(user_message) > 180 else user_message
        
        return f"""Quick analysis: "{short_message}"
Current state: {current_state}

Format: category|state
Where:
category: factual/philosophical/problem_solving/sensitive
state: greeting/fact_finding/problem_solving/closing

Answer:"""


class ProductionPredictiveCache:
    """
    Production-ready —Å–∏—Å—Ç–µ–º–∞ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
    """
    
    def __init__(self):
        # Thread-safe –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∫–µ—à
        self.l1_cache = {}  # –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø (LRU, 100 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        self.l2_cache = {}  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–µ—à (1000 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        
        # Thread safety locks
        self.l1_lock = threading.Lock()
        self.l2_lock = threading.Lock()
        self.prediction_lock = threading.Lock()
        
        # LRU –¥–ª—è L1 –∫–µ—à–∞
        self.l1_order = deque(maxlen=100)
        
        # –ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –ª–∏–º–∏—Ç–∞–º–∏
        self.prediction_patterns = defaultdict(list)
        self.query_sequences = deque(maxlen=500)
        
        # –õ–∏–º–∏—Ç—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è memory leak
        self.max_prediction_patterns = 200
        self.max_patterns_per_key = 5
        
        # TTL –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
        self.ttl_config = {
            'factual': 86400,     # 24 —á–∞—Å–∞ (—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã)
            'philosophical': 3600, # 1 —á–∞—Å (–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ)
            'problem_solving': 7200, # 2 —á–∞—Å–∞ (—Å–∏—Ç—É–∞—Ü–∏–æ–Ω–Ω—ã–µ)
            'sensitive': 1800      # 30 –º–∏–Ω—É—Ç (–¥–µ–ª–∏–∫–∞—Ç–Ω—ã–µ)
        }
        
        # Thread-safe —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'l1_hits': 0, 'l1_misses': 0,
            'l2_hits': 0, 'l2_misses': 0,
            'predictions_made': 0, 'predictions_hit': 0
        }
        self.stats_lock = threading.Lock()
        
        self.logger = logging.getLogger(f"{__name__}.PredictiveCache")
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º cleanup
        atexit.register(self.cleanup)
    
    def get(self, key: str, category: str = 'factual') -> Optional[Any]:
        """Thread-safe –ø–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ –∫–µ—à–∞"""
        current_time = time.time()
        ttl = self.ttl_config.get(category, 3600)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º L1 –∫–µ—à (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π)
        with self.l1_lock:
            if key in self.l1_cache:
                entry = self.l1_cache[key]
                if current_time - entry['timestamp'] < ttl:
                    self._update_l1_order_unsafe(key)
                    with self.stats_lock:
                        self.stats['l1_hits'] += 1
                    return entry['value']
                else:
                    del self.l1_cache[key]
                    if key in self.l1_order:
                        self.l1_order.remove(key)
        
        with self.stats_lock:
            self.stats['l1_misses'] += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º L2 –∫–µ—à
        with self.l2_lock:
            if key in self.l2_cache:
                entry = self.l2_cache[key]
                if current_time - entry['timestamp'] < ttl:
                    # –ü—Ä–æ–¥–≤–∏–≥–∞–µ–º –≤ L1 –∫–µ—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
                    self._promote_to_l1(key, entry['value'])
                    with self.stats_lock:
                        self.stats['l2_hits'] += 1
                    return entry['value']
                else:
                    del self.l2_cache[key]
        
        with self.stats_lock:
            self.stats['l2_misses'] += 1
        return None
    
    def set(self, key: str, value: Any, category: str = 'factual'):
        """Thread-safe —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ–º"""
        timestamp = time.time()
        entry = {'value': value, 'timestamp': timestamp, 'category': category}
        
        # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ L2
        with self.l2_lock:
            self.l2_cache[key] = entry
            self._cleanup_l2_if_needed()
        
        # –î–ª—è —á–∞—Å—Ç—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å—Ä–∞–∑—É –≤ L1
        if category in ['factual', 'sensitive']:
            self._promote_to_l1(key, value)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self._update_prediction_patterns(key)
    
    def _promote_to_l1(self, key: str, value: Any):
        """Thread-safe –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ L1 –∫–µ—à"""
        with self.l1_lock:
            if len(self.l1_cache) >= 100:
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç
                if self.l1_order:
                    oldest_key = self.l1_order.popleft()
                    if oldest_key in self.l1_cache:
                        del self.l1_cache[oldest_key]
            
            self.l1_cache[key] = {'value': value, 'timestamp': time.time()}
            if key in self.l1_order:
                self.l1_order.remove(key)
            self.l1_order.append(key)
    
    def _update_l1_order_unsafe(self, key: str):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –≤ L1 –∫–µ—à–µ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ lock)"""
        if key in self.l1_order:
            self.l1_order.remove(key)
        self.l1_order.append(key)
    
    def _update_prediction_patterns(self, key: str):
        """Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        with self.prediction_lock:
            self.query_sequences.append(key)
            
            # Cleanup prediction patterns –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
            if len(self.prediction_patterns) > self.max_prediction_patterns:
                # –£–¥–∞–ª—è–µ–º –ø–æ–ª–æ–≤–∏–Ω—É —Å—Ç–∞—Ä—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                keys_to_remove = list(self.prediction_patterns.keys())[:self.max_prediction_patterns // 2]
                for k in keys_to_remove:
                    del self.prediction_patterns[k]
                
                self.logger.info(f"üßπ Prediction patterns cleanup: —É–¥–∞–ª–µ–Ω–æ {len(keys_to_remove)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 –∑–∞–ø—Ä–æ—Å–∞—Ö
            if len(self.query_sequences) >= 3:
                recent = list(self.query_sequences)[-10:]
                for i in range(len(recent) - 2):
                    pattern = f"{recent[i]}|{recent[i+1]}"
                    next_query = recent[i+2]
                    
                    if next_query not in self.prediction_patterns[pattern]:
                        self.prediction_patterns[pattern].append(next_query)
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω
                        if len(self.prediction_patterns[pattern]) > self.max_patterns_per_key:
                            self.prediction_patterns[pattern] = self.prediction_patterns[pattern][-self.max_patterns_per_key:]
    
    def _cleanup_l2_if_needed(self):
        """Thread-safe –æ—á–∏—Å—Ç–∫–∞ L2 –∫–µ—à–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ lock)"""
        if len(self.l2_cache) > 1000:
            # –£–¥–∞–ª—è–µ–º 20% —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            current_time = time.time()
            items_by_age = [(k, v['timestamp']) for k, v in self.l2_cache.items()]
            items_by_age.sort(key=lambda x: x[1])
            
            to_remove = items_by_age[:200]  # 20% –æ—Ç 1000
            for key, _ in to_remove:
                if key in self.l2_cache:
                    del self.l2_cache[key]
            
            self.logger.info(f"üßπ L2 cache cleanup: —É–¥–∞–ª–µ–Ω–æ {len(to_remove)} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π")
    
    def get_efficiency_stats(self) -> Dict[str, float]:
        """Thread-safe —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–µ—à–∞"""
        with self.stats_lock:
            stats = self.stats.copy()
        
        total_l1 = stats['l1_hits'] + stats['l1_misses']
        total_l2 = stats['l2_hits'] + stats['l2_misses']
        
        l1_rate = (stats['l1_hits'] / max(total_l1, 1)) * 100
        l2_rate = (stats['l2_hits'] / max(total_l2, 1)) * 100
        
        with self.l1_lock:
            l1_size = len(self.l1_cache)
        with self.l2_lock:
            l2_size = len(self.l2_cache)
        
        return {
            'l1_hit_rate': round(l1_rate, 1),
            'l2_hit_rate': round(l2_rate, 1),
            'cache_sizes': {'l1': l1_size, 'l2': l2_size}
        }
    
    def cleanup(self):
        """Cleanup –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            with self.l1_lock:
                self.l1_cache.clear()
                self.l1_order.clear()
            
            with self.l2_lock:
                self.l2_cache.clear()
            
            with self.prediction_lock:
                self.prediction_patterns.clear()
                self.query_sequences.clear()
            
            self.logger.info("üßπ PredictiveCache cleanup completed")
        except Exception as e:
            self.logger.error(f"PredictiveCache cleanup error: {e}")


class ProductionIntelligentAnalyzer:
    """
    Production-ready –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Production-ready –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.hot_path = ProductionHotPathOptimizer()
        self.cache = ProductionPredictiveCache()
        self.prompt_builder = MicroPromptBuilder()
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ matching
        self.fast_keywords = {
            'factual': ['—Ü–µ–Ω–∞', '–∫—É—Ä—Å', '–≤—Ä–µ–º—è', '–≤–æ–∑—Ä–∞—Å—Ç', '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ'],
            'philosophical': ['–ø—Ä–∞–≤–∏–ª—å–Ω–æ', '–ø—Ä–∏–Ω—Ü–∏–ø—ã', '–≤–æ—Å–ø–∏—Ç–∞–Ω–∏–µ', '—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ'],
            'problem_solving': ['–ø—Ä–æ–±–ª–µ–º–∞', '–Ω–µ —Å–ª—É—à–∞–µ—Ç—Å—è', '–ø–æ–º–æ–≥–∏—Ç–µ', '–∫–∞–ø—Ä–∏–∑—ã'],
            'sensitive': ['–±–æ–ª–µ–∑–Ω—å', '—Å–º–µ—Ä—Ç—å', '—Ä–∞–∑–≤–æ–¥', '—Ç—Ä–∞–≤–º–∞']
        }
        
        # Thread-safe —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_stats = {
            'total_analyses': 0,
            'hot_path_hits': 0,
            'cache_hits': 0,
            'llm_calls_made': 0,
            'llm_calls_saved': 0,
            'avg_analysis_time': 0,
            'total_time_saved': 0
        }
        self.performance_lock = threading.Lock()
        
        self.prev_query_key = None
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º cleanup
        atexit.register(self.cleanup)
        
        self.logger.info("üöÄ Production-ready Intelligent Analyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def analyze_question_category_optimized(self, user_message: str, 
                                          conversation_history: List[str] = None) -> str:
        """
        Production-ready –∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–ø—Ä–æ—Å–∞
        """
        analysis_start = time.time()
        
        with self.performance_lock:
            self.performance_stats['total_analyses'] += 1
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        normalized_message = self._normalize_text_fast(user_message)
        cache_key = self._generate_fast_cache_key(normalized_message, "category")
        
        # Hot path –¥–ª—è —á–∞—Å—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        hot_result = self.hot_path.quick_classify(user_message)
        if hot_result:
            category, _ = hot_result
            with self.performance_lock:
                self.performance_stats['hot_path_hits'] += 1
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return category
        
        # Predictive cache –ø—Ä–æ–≤–µ—Ä–∫–∞
        cached_result = self.cache.get(cache_key, 'factual')
        if cached_result:
            with self.performance_lock:
                self.performance_stats['cache_hits'] += 1
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return cached_result
        
        # Fast keyword matching
        fast_category = self._fast_keyword_match(user_message)
        if fast_category:
            self.cache.set(cache_key, fast_category, fast_category)
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return fast_category
        
        # Micro-prompt LLM call –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        with self.performance_lock:
            self.performance_stats['llm_calls_made'] += 1
        
        micro_prompt = self.prompt_builder.build_micro_category_prompt(user_message)
        
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±—Ä–∞–Ω circular import
            result = self._safe_llm_call(micro_prompt).strip().lower()
            
            valid_categories = ['factual', 'philosophical', 'problem_solving', 'sensitive']
            if result in valid_categories:
                self.cache.set(cache_key, result, result)
                self._update_performance_stats(analysis_start, saved_llm_call=False)
                return result
            else:
                fallback = 'factual'
                self.cache.set(cache_key, fallback, fallback)
                self._update_performance_stats(analysis_start, saved_llm_call=False)
                return fallback
                
        except Exception as e:
            self.logger.error(f"Micro-prompt analysis error: {e}")
            fallback = 'factual'
            self.cache.set(cache_key, fallback, fallback)
            self._update_performance_stats(analysis_start, saved_llm_call=False)
            return fallback
    
    def analyze_lead_state_optimized(self, user_message: str, current_state: str, 
                                   conversation_history: List[str] = None) -> str:
        """
        Production-ready –∞–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ª–∏–¥–∞
        """
        analysis_start = time.time()
        
        # Hot path –¥–ª—è –ø—Ä—è–º—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        hot_result = self.hot_path.quick_classify(user_message)
        if hot_result:
            _, state = hot_result
            with self.performance_lock:
                self.performance_stats['hot_path_hits'] += 1
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return state
        
        # Cache check
        cache_key = self._generate_fast_cache_key(f"{user_message}|{current_state}", "state")
        cached_result = self.cache.get(cache_key, 'factual')
        if cached_result:
            with self.performance_lock:
                self.performance_stats['cache_hits'] += 1
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return cached_result
        
        # Fast state transitions –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        if len(user_message.split()) < 5:
            self.cache.set(cache_key, current_state, 'factual')
            self._update_performance_stats(analysis_start, saved_llm_call=True)
            return current_state
        
        # Micro-prompt –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        with self.performance_lock:
            self.performance_stats['llm_calls_made'] += 1
        
        micro_prompt = self.prompt_builder.build_micro_state_prompt(user_message, current_state)
        
        try:
            result = self._safe_llm_call(micro_prompt).strip().lower()
            
            valid_states = ['greeting', 'fact_finding', 'problem_solving', 'closing']
            if result in valid_states:
                self.cache.set(cache_key, result, 'factual')
                self._update_performance_stats(analysis_start, saved_llm_call=False)
                return result
            else:
                self.cache.set(cache_key, current_state, 'factual')
                self._update_performance_stats(analysis_start, saved_llm_call=False)
                return current_state
                
        except Exception as e:
            self.logger.error(f"State analysis error: {e}")
            self.cache.set(cache_key, current_state, 'factual')
            self._update_performance_stats(analysis_start, saved_llm_call=False)
            return current_state
    
    def _safe_llm_call(self, prompt: str) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: Safe LLM call –±–µ–∑ circular import
        –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ - –≤ –ø—Ä–æ–¥–∞–∫—à–Ω –≤–µ—Ä—Å–∏–∏ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç inject LLM service
        """
        # –í –ø—Ä–æ–¥–∞–∫—à–Ω –≤–µ—Ä—Å–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç injected LLM service
        return "factual"  # Fallback
    
    def _normalize_text_fast(self, text: str) -> str:
        """–ë—ã—Å—Ç—Ä–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        return ' '.join(text.lower().split())[:100]
    
    def _generate_fast_cache_key(self, text: str, analysis_type: str) -> str:
        """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞"""
        return hashlib.md5(f"{text}|{analysis_type}".encode()).hexdigest()[:16]
    
    def _fast_keyword_match(self, user_message: str) -> Optional[str]:
        """–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏"""
        message_lower = user_message.lower()
        
        for category in ['factual', 'sensitive', 'problem_solving', 'philosophical']:
            keywords = self.fast_keywords[category]
            if any(keyword in message_lower for keyword in keywords):
                return category
        
        return None
    
    def _update_performance_stats(self, start_time: float, saved_llm_call: bool):
        """Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        analysis_time = time.time() - start_time
        
        with self.performance_lock:
            if saved_llm_call:
                self.performance_stats['llm_calls_saved'] += 1
                self.performance_stats['total_time_saved'] += 2.0
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞
            current_avg = self.performance_stats['avg_analysis_time']
            total_analyses = self.performance_stats['total_analyses']
            new_avg = (current_avg * (total_analyses - 1) + analysis_time) / total_analyses
            self.performance_stats['avg_analysis_time'] = new_avg
    
    def analyze_philosophical_loop_fast(self, conversation_history: List[str]) -> Tuple[bool, int]:
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏—Ö —Ü–∏–∫–ª–æ–≤ –±–µ–∑ LLM"""
        if not conversation_history:
            return False, 0
        
        user_messages = [msg for msg in conversation_history if msg.startswith("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:")][-5:]
        
        philosophical_count = 0
        philosophical_keywords = self.fast_keywords['philosophical']
        
        for message in reversed(user_messages):
            message_text = message.replace("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:", "").strip().lower()
            if any(keyword in message_text for keyword in philosophical_keywords):
                philosophical_count += 1
            else:
                break
        
        return philosophical_count >= 3, philosophical_count
    
    def should_use_humor_taboo_fast(self, user_message: str) -> bool:
        """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±—É –Ω–∞ —é–º–æ—Ä"""
        message_lower = user_message.lower()
        sensitive_keywords = self.fast_keywords['sensitive']
        return any(keyword in message_lower for keyword in sensitive_keywords)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Thread-safe –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        with self.performance_lock:
            stats = self.performance_stats.copy()
        
        # –í—ã—á–∏—Å–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        if stats['total_analyses'] > 0:
            stats['cache_hit_rate'] = round((stats['cache_hits'] / stats['total_analyses']) * 100, 1)
            stats['hot_path_rate'] = round((stats['hot_path_hits'] / stats['total_analyses']) * 100, 1)
            stats['llm_avoidance_rate'] = round((stats['llm_calls_saved'] / stats['total_analyses']) * 100, 1)
            
            baseline_time_per_analysis = 2.0
            stats['estimated_speedup'] = round(baseline_time_per_analysis / max(stats['avg_analysis_time'], 0.1), 2)
            stats['cost_savings_percent'] = round((stats['llm_calls_saved'] / (stats['llm_calls_made'] + stats['llm_calls_saved'])) * 100, 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º cache efficiency
        stats['cache_efficiency'] = self.cache.get_efficiency_stats()
        
        return stats
    
    def cleanup(self):
        """Cleanup –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            # Cleanup —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
            with self.performance_lock:
                self.performance_stats.clear()
            
            self.logger.info("üßπ IntelligentAnalyzer cleanup completed")
        except Exception as e:
            self.logger.error(f"IntelligentAnalyzer cleanup error: {e}")


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä production-ready –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
intelligent_analyzer_production = ProductionIntelligentAnalyzer()